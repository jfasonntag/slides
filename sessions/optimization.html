<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Florian Oswald" />
  <title>Computational Economics: Unconstrained Optimization</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; background-color: #dddddd; }
td.sourceCode { padding-left: 5px; }
code > span.kw { font-weight: bold; } /* Keyword */
code > span.dt { color: #800000; } /* DataType */
code > span.dv { color: #0000ff; } /* DecVal */
code > span.bn { color: #0000ff; } /* BaseN */
code > span.fl { color: #800080; } /* Float */
code > span.ch { color: #ff00ff; } /* Char */
code > span.st { color: #dd0000; } /* String */
code > span.co { color: #808080; font-style: italic; } /* Comment */
code > span.al { color: #00ff00; font-weight: bold; } /* Alert */
code > span.fu { color: #000080; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #ff0000; font-weight: bold; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #ff00ff; } /* SpecialChar */
code > span.vs { color: #dd0000; } /* VerbatimString */
code > span.ss { color: #dd0000; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { } /* Variable */
code > span.cf { } /* ControlFlow */
code > span.op { } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { font-weight: bold; } /* Preprocessor */
code > span.at { } /* Attribute */
code > span.do { color: #808080; font-style: italic; } /* Documentation */
code > span.an { color: #808080; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #808080; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #808080; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="http://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script src="http://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Computational Economics: Unconstrained Optimization</h1>
  <p class="author">
Florian Oswald
  </p>
  <p class="date">Sciences Po, 2016</p>
</div>
<div id="some-taxonomy-and-initial-examples" class="slide section level1">
<h1>Some Taxonomy and Initial Examples</h1>
<ul>
<li>In most of the examples to follow, we talk about <em>minimization</em> of a function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>. Everything we do also applies to maximization, since <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>min</mo><mi>x</mi></msub><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><msub><mo>max</mo><mi>x</mi></msub><mo>−</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\min_x f(x) = \max_x -f(x)</annotation></semantics></math>.</li>
<li><p>Here is a generic optimization problem: <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>min</mo><mrow><mi>x</mi><mo>∈</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup></mrow></munder><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mspace width="1.0em"></mspace><mi>s</mi><mi>.</mi><mi>t</mi><mi>.</mi><mspace width="1.0em"></mspace><mtable><mtr><mtd><msub><mi>c</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mn>0</mn><mo>,</mo></mtd><mtd><mi>i</mi><mo>∈</mo><mi>E</mi></mtd></mtr><mtr><mtd><msub><mi>c</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>≥</mo><mn>0</mn><mo>,</mo></mtd><mtd><mi>i</mi><mo>∈</mo><mi>I</mi></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex"> \min_{x\in\mathbb{R}^n} f(x)  \quad  s.t.\quad \begin{array} c_i(x) = 0, &amp; i\in E \\
                                                          c_i(x) \geq 0, &amp; i\in I \end{array}
                                                          </annotation></semantics></math></p></li>
<li>This is a general way of writing an optimization problem. E are all indices as equality constraints, I are all inequality constraints.</li>
<li>An example of such a problem might be <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>min</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>−</mo><mn>2</mn><msup><mo stretchy="false" form="postfix">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo>−</mo><mn>1</mn><msup><mo stretchy="false" form="postfix">)</mo><mn>2</mn></msup><mspace width="1.0em"></mspace><mi>s</mi><mi>.</mi><mi>t</mi><mi>.</mi><mspace width="1.0em"></mspace><mtable><mtr><mtd><msubsup><mi>x</mi><mn>1</mn><mn>2</mn></msubsup><mo>−</mo><msub><mi>x</mi><mn>2</mn></msub><mo>≤</mo><mn>0</mn></mtd></mtr><mtr><mtd><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>x</mi><mn>2</mn></msub><mo>≤</mo><mn>2</mn></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex"> \min (x_1 -2)^2 + (x_2 -1)^2 \quad  s.t.\quad \begin{array} x_{1}^2 -x_2 \leq 0 \\
                                                          x_1 +x_2 \leq 2 \end{array}
                                                          </annotation></semantics></math></li>
<li><p>Here is a picture of that problem taken from the textbook <span class="citation">(Nocedal and Wright 2006)</span> ( for copyright reasons, I cannot show this in the online version of the slides. ):</p></li>
</ul>
<div class="figure">
<img src="figs-restricted/feasible-region.png" alt="Figure 1.1 in (Nocedal and Wright 2006)" />
<p class="caption">Figure 1.1 in <span class="citation">(Nocedal and Wright 2006)</span></p>
</div>
</div>
<div id="kinds-of-problems-considered" class="slide section level1">
<h1>Kinds of problems considered</h1>
<ul>
<li>Don't talk about stochastic optimization methods:
<ul>
<li>Simluated Annealing</li>
<li>MCMC</li>
<li>other Stochastic Search Methods</li>
<li>A gentle introduction is <span class="citation">(Robert and Casella 2009)</span></li>
</ul></li>
</ul>
</div>
<div id="transportation-problem" class="slide section level1">
<h1>Transportation Problem</h1>
<blockquote>
<p>A chemical company has two factories <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mn>1</mn></msub><mo>,</mo><msub><mi>F</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">F_1,F_2</annotation></semantics></math> and a dozen retail outlets <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>R</mi><mn>12</mn></msub></mrow><annotation encoding="application/x-tex">R_1,\dots,R_{12}</annotation></semantics></math>. Each factory <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> can produce at most <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>a</mi><mi>i</mi></msub><annotation encoding="application/x-tex">a_i</annotation></semantics></math> tons of output each week. Each retail outlet <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math> has a weekly demand of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>b</mi><mi>j</mi></msub><annotation encoding="application/x-tex">b_j</annotation></semantics></math> tons per week. The cost of shipping from <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>F</mi><mi>i</mi></msub><annotation encoding="application/x-tex">F_i</annotation></semantics></math> to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>R</mi><mi>j</mi></msub><annotation encoding="application/x-tex">R_j</annotation></semantics></math> is given by <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>c</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">c_{ij}</annotation></semantics></math>. How much of the product to ship from each factory to each outlet, minimize cost, and satisfy all constraints? let's call <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">x_{ij}</annotation></semantics></math> the number of tons shipped from <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>.</p>
</blockquote>
<div class="figure">
<img src="figs-restricted/transportation.png" alt="Figure 1.2 in (Nocedal and Wright 2006)" />
<p class="caption">Figure 1.2 in <span class="citation">(Nocedal and Wright 2006)</span></p>
</div>
<div class="incremental">
<ul>
<li><p>A mathematical formulation of this problem is <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><mo>min</mo><munder><mo>∑</mo><mrow><mi>i</mi><mi>j</mi></mrow></munder><msub><mi>c</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="right"><mtext mathvariant="normal">subject to</mtext><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mn>12</mn></munderover><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>≤</mo><msub><mi>a</mi><mi>i</mi></msub><mo>,</mo><mspace width="1.0em"></mspace><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn></mtd></mtr><mtr><mtd columnalign="right"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>2</mn></munderover><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>≥</mo><msub><mi>b</mi><mi>j</mi></msub><mo>,</mo><mspace width="1.0em"></mspace><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mn>12</mn></mtd></mtr><mtr><mtd columnalign="right"><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>≥</mo><mn>0</mn><mo>,</mo><mspace width="1.0em"></mspace><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mn>12</mn></mtd></mtr></mtable><annotation encoding="application/x-tex"> \begin{align}
    \min \sum_{ij} c_{ij} x_{ij} \\
    \text{subject to} \sum_{j=1}^{12} x_{ij} \leq a_i,\quad i=1,2 \\
    \sum_{i=1}^2  x_{ij} \geq b_j,\quad j=1,\dots,12  \\
    x_{ij} \geq 0, \quad i=1,2,j=1,\dots,12
    \end{align}
    </annotation></semantics></math></p></li>
<li>This is called a <em>linear programming</em> problem, because both objective function and all constrains are linear.</li>
<li><p>With any of those being nonlinear, we would call this a non-linear problem.</p></li>
</ul>
</div>
</div>
<div id="constrained-vs-unconstrained" class="slide section level1">
<h1>Constrained vs Unconstrained</h1>
<ul>
<li>There are many applications of both in economics.</li>
<li>Unconstrained: maximimum likelihood</li>
<li>Constrained: MPEC</li>
<li>It is sometimes possible to transform a constrained problem into an unconstrained one.</li>
</ul>
</div>
<div id="convexity" class="slide section level1">
<h1>Convexity</h1>
<ul>
<li>Convex problems are easier to solve.</li>
<li>What is convex?</li>
</ul>
<blockquote>
<p>A set <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>∈</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">S\in\mathbb{R}^n</annotation></semantics></math> is convex if the straight line segment connecting any two points in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math> lies entirely inside <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>. A function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> is a convex function, if its domain <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math> is a convex set, and for any two points <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>,</mo><mi>y</mi><mo>∈</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">x,y \in S</annotation></semantics></math>, we have that <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>α</mi><mi>x</mi><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="false" form="postfix">)</mo><mi>y</mi><mo stretchy="false" form="postfix">)</mo><mo>≤</mo><mi>α</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="false" form="postfix">)</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>y</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex"> f(\alpha x + (1-\alpha)y) \leq \alpha f(x) + (1-\alpha) f(y) </annotation></semantics></math> for all <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>∈</mo><mo stretchy="false" form="prefix">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\alpha \in [0,1]</annotation></semantics></math></p>
</blockquote>
<ul>
<li>Simple instances of convex sets are the unit ball <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><mi>y</mi><mo>∈</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup><mo>,</mo><mo stretchy="false" form="postfix">‖</mo><mi>y</mi><msub><mo stretchy="false" form="postfix">‖</mo><mn>2</mn></msub><mo>≤</mo><mn>1</mn><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{y \in \mathbb{R}^n, \Vert y\Vert_2 \leq 1\}</annotation></semantics></math>, and any set defined by linear equalities and inequalities.</li>
<li><em>convex Programming</em> describes a special case of the introductory minimizatin problem where
<ul>
<li>the objective function is convex,</li>
<li>the equality constrains are linear, and</li>
<li>the inequality constraints are concave.</li>
</ul></li>
</ul>
</div>
<div id="optimization-algorithms" class="slide section level1">
<h1>Optimization Algorithms</h1>
<ul>
<li>All of the algorithms we are going to see employ some kind of <em>iterative</em> proceedure.</li>
<li>They try to improve the value of the objective function over successive steps.</li>
<li>The way the algorithm goes about generating the next step is what distinguishes algorithms from one another.
<ul>
<li>Some algos only use the objective function</li>
<li>Some use both objective and gradients</li>
<li>Some add the Hessian</li>
<li>and many variants more</li>
</ul></li>
</ul>
<div class="incremental">
<h2 id="desirable-features-of-any-algorithm">Desirable Features of any Algorithm</h2>
<ul>
<li>Robustness: We want good performance on a wide variety of problems in their class, and starting from <em>all</em> reasonable starting points.</li>
<li>Efficiency: They should be fast and not use an excessive amount of memory.</li>
<li>Accuracy: They should identify the solution with high precision.</li>
</ul>
<h2 id="a-word-of-caution">A Word of Caution</h2>
<ul>
<li>You should <strong>not</strong> normally attempt to write a numerical optimizer for yourself.</li>
<li>Entire generations of Applied Mathematicians and other numerical pro's have worked on those topics before you, so you should use their work.
<ul>
<li>Any optimizer you could come up with is probably going to perform below par, and be highly likely to contain mistakes.</li>
<li>Don't reinvent the wheel.</li>
</ul></li>
<li>That said, it's very important that we understand some basics about the main algorithms, because your task is <strong>to choose from the wide array of available ones</strong>.</li>
</ul>
</div>
</div>
<div id="unconstrained-optimization-what-is-a-solution" class="slide section level1">
<h1>Unconstrained Optimization: What is a solution?</h1>
<ul>
<li>A typical unconstrained optimization problem will look something like this: <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>min</mo><mi>x</mi></munder><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>,</mo><mspace width="1.0em"></mspace><mi>x</mi><mo>∈</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup></mrow><annotation encoding="application/x-tex"> \min_x f(x),\quad x\in \mathbb{R}^n </annotation></semantics></math> and where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>:</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup><mo accent="false">↦</mo><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle></mrow><annotation encoding="application/x-tex">f : \mathbb{R}^n \mapsto \mathbb{R}</annotation></semantics></math> is a smooth function.</li>
<li>In general, we would always like to find a <em>global</em> minimizer, i.e.
<div class="center" style="width: auto; margin-left: auto; margin-right: auto;">
a point <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>x</mi><mo>*</mo></msup><annotation encoding="application/x-tex">x^*</annotation></semantics></math> where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mo>*</mo></msup><mo stretchy="false" form="postfix">)</mo><mo>≤</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mspace width="1.0em"></mspace><mo>∀</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">f(x^*) \leq f(x)\quad \forall x</annotation></semantics></math>
</div></li>
<li>Since our algorithm is not going to visit many points in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup><annotation encoding="application/x-tex">\mathbb{R}^n</annotation></semantics></math> (or so we hope), we can never be totally sure that we find a global optimizer.</li>
<li>Most optimizers can only find a <em>local</em> minimizer. That is a point
<div class="center" style="width: auto; margin-left: auto; margin-right: auto;">
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>x</mi><mo>*</mo></msup><annotation encoding="application/x-tex">x^*</annotation></semantics></math> where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mo>*</mo></msup><mo stretchy="false" form="postfix">)</mo><mo>≤</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mspace width="1.0em"></mspace><mo>∀</mo><mi>x</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒩</mi></mstyle></mrow><annotation encoding="application/x-tex">f(x^*) \leq f(x)\quad \forall x \in \mathcal{N}</annotation></semantics></math> where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="script"><mi>𝒩</mi></mstyle><annotation encoding="application/x-tex">\mathcal{N}</annotation></semantics></math> is a neighborhood around <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>x</mi><mo>*</mo></msup><annotation encoding="application/x-tex">x^*</annotation></semantics></math>.
</div></li>
<li>Global minization can be very hard sometimes.</li>
</ul>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Eggholder_function.pdf/page1-800px-Eggholder_function.pdf.jpg" alt="Global min at f(512, 404.2319). By Gaortizg GFDL or CC BY-SA 3.0, via Wikimedia Commons" />
<p class="caption">Global min at <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mn>512</mn><mo>,</mo><mn>404.2319</mn><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">f(512, 404.2319)</annotation></semantics></math>. By Gaortizg <a href="http://www.gnu.org/copyleft/fdl.html">GFDL</a> or <a href="http://creativecommons.org/licenses/by-sa/3.0">CC BY-SA 3.0</a>, via Wikimedia Commons</p>
</div>
</div>
<div id="unconstrained-optimization-in-julia" class="slide section level1">
<h1>(Unconstrained) Optimization in <code>Julia</code></h1>
<ul>
<li>Umbrella Organisation: <a href="http://www.juliaopt.org"><code>http://www.juliaopt.org</code></a>
<ul>
<li>We will make ample use of this when we talk about constrained optimsation.</li>
<li>The Julia Interface to the very well established <a href="http://ab-initio.mit.edu/wiki/index.php/NLopt">C-Library NLopt</a> is called <a href="https://github.com/JuliaOpt/NLopt.jl"><code>NLopt.jl</code></a>. One could use <code>NLopt</code> without constraints in an unconstrained problem.</li>
</ul></li>
<li><a href="https://github.com/JuliaLang/Roots.jl"><code>Roots.jl</code></a>: Simple algorithms that find the zeros of a univariate function.</li>
<li>Baseline Collection of unconstrained optimization algorithms: <a href="https://github.com/JuliaOpt/Optim.jl"><code>Optim.jl</code></a></li>
</ul>
</div>
<div id="introducing-optim.jl" class="slide section level1">
<h1>Introducing <a href="https://github.com/JuliaOpt/Optim.jl"><code>Optim.jl</code></a></h1>
<ul>
<li>Multipurpose unconstrained optimization package
<ul>
<li>provides 8 different algorithms</li>
<li>univariate optimization without derivatives</li>
</ul></li>
</ul>
<h3 id="introducing-rosenbrocks-banana-function">Introducing <a href="https://en.wikipedia.org/wiki/Rosenbrock_function">Rosenbrock's Banana</a> function</h3>
<p>The Banana function is defined by <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mo stretchy="false" form="prefix">(</mo><mi>a</mi><mo>−</mo><mi>x</mi><msup><mo stretchy="false" form="postfix">)</mo><mn>2</mn></msup><mo>+</mo><mi>b</mi><mo stretchy="false" form="prefix">(</mo><mi>y</mi><mo>−</mo><msup><mi>x</mi><mn>2</mn></msup><msup><mo stretchy="false" form="postfix">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex"> f(x,y) = (a-x)^2  + b(y-x^2)^2  </annotation></semantics></math></p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/3/32/Rosenbrock_function.svg" alt="Banana for a = 0. By Gaortizg GFDL or CC BY-SA 3.0, via Wikimedia Commons" />
<p class="caption">Banana for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">a = 0</annotation></semantics></math>. By Gaortizg <a href="http://www.gnu.org/copyleft/fdl.html">GFDL</a> or <a href="http://creativecommons.org/licenses/by-sa/3.0">CC BY-SA 3.0</a>, via Wikimedia Commons</p>
</div>
<h3 id="what-is-the-minimum-of-that-function">What is the minimum of that function?</h3>
<ul>
<li>For <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>b</mi><mo>=</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">a=1,b=100</annotation></semantics></math>, what is the global minimum of that function?</li>
<li>What are the inputs one needs to supply to an algorithm in a more general example?</li>
</ul>
</div>
<div id="rosenbrock-banana-and-optim.jl" class="slide section level1">
<h1>Rosenbrock Banana and Optim.jl</h1>
<ul>
<li>We will use <code>Optim</code> for the rest of this lecture.</li>
<li>We need to supply the objective function and - depending on the solution algorithm - the gradient and hessian as well.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia"><span class="kw">function</span> rosenbrock(x::<span class="dt">Vector</span>)
    <span class="kw">return</span> (<span class="fl">1.0</span> - x[<span class="fl">1</span>])^<span class="fl">2</span> + <span class="fl">100.0</span> * (x[<span class="fl">2</span>] - x[<span class="fl">1</span>]^<span class="fl">2</span>)^<span class="fl">2</span>
<span class="kw">end</span>

<span class="kw">function</span> rosenbrock_gradient!(x::<span class="dt">Vector</span>, storage::<span class="dt">Vector</span>)
    storage[<span class="fl">1</span>] = -<span class="fl">2.0</span> * (<span class="fl">1.0</span> - x[<span class="fl">1</span>]) - <span class="fl">400.0</span> * (x[<span class="fl">2</span>] - x[<span class="fl">1</span>]^<span class="fl">2</span>) * x[<span class="fl">1</span>]
    storage[<span class="fl">2</span>] = <span class="fl">200.0</span> * (x[<span class="fl">2</span>] - x[<span class="fl">1</span>]^<span class="fl">2</span>)
<span class="kw">end</span>

<span class="kw">function</span> rosenbrock_hessian!(x::<span class="dt">Vector</span>, storage::<span class="dt">Matrix</span>)
    storage[<span class="fl">1</span>, <span class="fl">1</span>] = <span class="fl">2.0</span> - <span class="fl">400.0</span> * x[<span class="fl">2</span>] + <span class="fl">1200.0</span> * x[<span class="fl">1</span>]^<span class="fl">2</span>
    storage[<span class="fl">1</span>, <span class="fl">2</span>] = -<span class="fl">400.0</span> * x[<span class="fl">1</span>]
    storage[<span class="fl">2</span>, <span class="fl">1</span>] = -<span class="fl">400.0</span> * x[<span class="fl">1</span>]
    storage[<span class="fl">2</span>, <span class="fl">2</span>] = <span class="fl">200.0</span>
<span class="kw">end</span></code></pre></div>
</div>
<div id="comparison-methods" class="slide section level1">
<h1>Comparison Methods</h1>
<ul>
<li>We will now look at a first class of algorithms, which are very simple, but sometimes a good starting point.</li>
<li>They just <em>compare</em> function values.</li>
<li><em>Grid Search</em> : Compute the objective function at <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo>=</mo><mo stretchy="false" form="prefix">{</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>x</mi><mi>N</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">G=\{x_1,\dots,x_N\}</annotation></semantics></math> and pick the highest value of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>.
<ul>
<li>This is very slow.</li>
<li>It requires large <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>.</li>
<li>But it's robust (will find global optimizer for large enough <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>)</li>
</ul></li>
</ul>
<div class="incremental">
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia"><span class="co"># grid search on rosenbrock</span>
grid = collect(-<span class="fl">1.0</span>:<span class="fl">0.1</span>:<span class="fl">3</span>);
grid2D = [[i;j] <span class="kw">for</span> i <span class="kw">in</span> grid,j <span class="kw">in</span> grid];
val2D = map(rosenbrock,grid2D);
r = findmin(val2D);
println(<span class="st">&quot;grid search results in minimizer = $(grid2D[r[2]])&quot;</span>)</code></pre></div>
</div>
</div>
<div id="the-golden-ratio-or-bracketing-search-for-1d-problems" class="slide section level1">
<h1>The Golden Ratio or Bracketing Search for 1D problems</h1>
<ul>
<li>A derivative-free method</li>
<li>a Bracketing method
<ul>
<li>find the local minimum of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> on <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">[</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">[a,b]</annotation></semantics></math></li>
<li>select 2 interior points <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mo>,</mo><mi>d</mi></mrow><annotation encoding="application/x-tex">c,d</annotation></semantics></math> such that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>&lt;</mo><mi>c</mi><mo>&lt;</mo><mi>d</mi><mo>&lt;</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a&lt;c&lt;d&lt;b</annotation></semantics></math>
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>c</mi><mo stretchy="false" form="postfix">)</mo><mo>≤</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>d</mi><mo stretchy="false" form="postfix">)</mo><mo accent="false">⟹</mo></mrow><annotation encoding="application/x-tex">f(c) \leq f(d) \implies</annotation></semantics></math> min must lie in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">[</mo><mi>a</mi><mo>,</mo><mi>d</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">[a,d]</annotation></semantics></math>. replace <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>b</mi><annotation encoding="application/x-tex">b</annotation></semantics></math> with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>d</mi><annotation encoding="application/x-tex">d</annotation></semantics></math>, start again with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">[</mo><mi>a</mi><mo>,</mo><mi>d</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">[a,d]</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>c</mi><mo stretchy="false" form="postfix">)</mo><mo>&gt;</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>d</mi><mo stretchy="false" form="postfix">)</mo><mo accent="false">⟹</mo></mrow><annotation encoding="application/x-tex">f(c) &gt; f(d) \implies</annotation></semantics></math> min must lie in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">[</mo><mi>c</mi><mo>,</mo><mi>b</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">[c,b]</annotation></semantics></math>. replace <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math> with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>, start again with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">[</mo><mi>c</mi><mo>,</mo><mi>b</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">[c,b]</annotation></semantics></math></li>
</ul></li>
<li>how to choose <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>,</mo><mi>d</mi></mrow><annotation encoding="application/x-tex">b,d</annotation></semantics></math> though?</li>
<li>we want the length of the interval to be independent of whether we replace upper or lower bound</li>
<li>we want to reuse the non-replaced point from the previous iteration.</li>
<li>these imply the golden rule:</li>
<li>new point <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><mi>a</mi><mo>+</mo><msub><mi>α</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>b</mi><mo>−</mo><mi>a</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">x_i = a + \alpha_i (b-a)</annotation></semantics></math>, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mn>1</mn></msub><mo>=</mo><mfrac><mrow><mn>3</mn><mo>−</mo><msqrt><mn>5</mn></msqrt></mrow><mn>2</mn></mfrac><mo>,</mo><msub><mi>α</mi><mn>2</mn></msub><mo>=</mo><mfrac><mrow><msqrt><mn>5</mn></msqrt><mo>−</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\alpha_1 = \frac{3-\sqrt{5}}{2},\alpha_2=\frac{\sqrt{5}-1}{2}</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mn>2</mn></msub><annotation encoding="application/x-tex">\alpha_2</annotation></semantics></math> is known as the <em>golden ratio</em>, well known for it's role in renaissance art.</li>
</ul></li>
</ul>
<h3 id="bracketing-search-in-julia">Bracketing Search in Julia</h3>
<ul>
<li>The package <a href="https://github.com/JuliaOpt/Optim.jl"><code>Optim.jl</code></a> provides an implementation of &quot;Brent's Method&quot; as well as the golden section search:</li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia">using Optim
using Gadfly
f(x) = exp(x) - x^<span class="fl">4</span>
minf(x) = -f(x)
plot(f,<span class="fl">0</span>,<span class="fl">2</span>)
brent = optimize(minf,<span class="fl">0</span>,<span class="fl">2</span>,method=:brent)
golden = optimize(minf,<span class="fl">0</span>,<span class="fl">2</span>,method=:golden_section)</code></pre></div>
<ul>
<li>how well does this do with many local minima?</li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia">g(x) = exp(x) - x^<span class="fl">4</span> +sin(<span class="fl">40</span>*x)
ming(x) = -g(x)
plot(g,<span class="fl">0</span>,<span class="fl">2</span>)
grid = collect(<span class="fl">0</span>:<span class="fl">0.0001</span>:<span class="fl">2</span>);
v,idx  = findmax(<span class="dt">Float64</span>[g(x) <span class="kw">for</span> x <span class="kw">in</span> grid])
println(<span class="st">&quot;grid maximizer is $(grid[idx])&quot;</span>)
golden = optimize(ming,<span class="fl">0</span>,<span class="fl">2</span>,method=:golden_section)
brent = optimize(ming,<span class="fl">0</span>,<span class="fl">2</span>,method=:brent)
using Base.Test
@test_approx_eq  grid[idx] golden.minimum
@test_approx_eq  grid[idx] brent.minimum</code></pre></div>
<ul>
<li>Not <em>very</em> well at all. You can easily see that this method only works for unimodal functions.</li>
<li>We get trapped in a local minimum here.</li>
</ul>
</div>
<div id="bracketing-for-multidimensional-problems-nelder-mead" class="slide section level1">
<h1>Bracketing for Multidimensional Problems: Nelder-Mead</h1>
<ul>
<li>The Goal here is to find the simplex containing the local minimizer <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>x</mi><mo>*</mo></msup><annotation encoding="application/x-tex">x^*</annotation></semantics></math></li>
<li>In the case where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> is n-D, this simplex has <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n+1</annotation></semantics></math> vertices</li>
<li>In the case where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> is 2-D, this simplex has <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2+1</annotation></semantics></math> vertices, i.e. it's a triangle.</li>
<li>The method proceeds by evaluating the function at all <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n+1</annotation></semantics></math> vertices, and by replacing the worst function value with a new guess.</li>
<li>this can be achieved by a sequence of moves:
<ul>
<li>reflect</li>
<li>expand</li>
<li>contract</li>
<li>shrink movements.</li>
</ul></li>
</ul>
<div class="center" style="width: auto; margin-left: auto; margin-right: auto;">
<img src="figs/neldermeadsteps.gif" />
</div>
<ul>
<li>this is a very popular method. The matlab functions <code>fmincon</code> and <code>fminsearch</code> implements it.</li>
<li>When it works, it works quite fast.</li>
<li>No derivatives required.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia">using Optim
optimize(rosenbrock, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :nelder_mead)</code></pre></div>
<ul>
<li>But.</li>
</ul>
</div>
<div id="bracketing-for-multidimensional-problems-comment-on-nelder-mead" class="slide section level1">
<h1>Bracketing for Multidimensional Problems: Comment on Nelder-Mead</h1>
<blockquote>
<p>Lagarias et al. (SIOPT, 1999): At present there is no function in any dimension greater than one, for which the original Nelder-Mead algorithm has been proved to converge to a minimizer.</p>
</blockquote>
<blockquote>
<p>Given all the known inefficiencies and failures of the Nelder-Mead algorithm [...], one might wonder why it is used at all, let alone why it is so extraordinarily popular.</p>
</blockquote>
</div>
<div id="reminder-optimality-conditions" class="slide section level1">
<h1>Reminder: Optimality Conditions</h1>
<h3 id="notation">Notation</h3>
<ul>
<li>Unless otherwise noted, we have <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∈</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">x \in \mathbb{R}^n</annotation></semantics></math> as an <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> element vector.</li>
<li>The <strong>gradient</strong> of a function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>:</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup><mo accent="false">↦</mo><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle></mrow><annotation encoding="application/x-tex">f : \mathbb{R}^n \mapsto \mathbb{R}</annotation></semantics></math> is denoted <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>∇</mi><mi>f</mi><mo>:</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup><mo accent="false">↦</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">\nabla f:\mathbb{R}^n \mapsto \mathbb{R}^n</annotation></semantics></math> a it returns a vector <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow><mrow><mi>∂</mi><msub><mi>x</mi><mn>1</mn></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>,</mo><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow><mrow><mi>∂</mi><msub><mi>x</mi><mn>2</mn></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>,</mo><mi>…</mi><mo>,</mo><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow><mrow><mi>∂</mi><msub><mi>x</mi><mi>n</mi></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> \nabla f(x) = \left(\frac{\partial f}{\partial x_1}(x),\frac{\partial f}{\partial x_2}(x),\dots,\frac{\partial f}{\partial x_n}(x) \right) </annotation></semantics></math></li>
<li>It's <strong>hessian</strong> is a function denoted <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>∇</mi><mn>2</mn></msup><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\nabla^2 f(x)</annotation></semantics></math> or <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mi>f</mi></msub><mo>:</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup><mo accent="false">↦</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">H_f :\mathbb{R}^n \mapsto \mathbb{R}^{n\times n}</annotation></semantics></math> and returns an <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>n</mi><mo>,</mo><mi>n</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(n,n)</annotation></semantics></math> matrix given by <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mi>f</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mtable><mtr><mtd columnalign="center"><mfrac><mrow><msup><mi>∂</mi><mn>2</mn></msup><mi>f</mi></mrow><mrow><mi>∂</mi><msub><mi>x</mi><mn>1</mn></msub><mi>∂</mi><msub><mi>x</mi><mn>1</mn></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd><mfrac><mrow><msup><mi>∂</mi><mn>2</mn></msup><mi>f</mi></mrow><mrow><mi>∂</mi><msub><mi>x</mi><mn>2</mn></msub><mi>∂</mi><msub><mi>x</mi><mn>1</mn></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd><mi>…</mi></mtd><mtd><mfrac><mrow><msup><mi>∂</mi><mn>2</mn></msup><mi>f</mi></mrow><mrow><mi>∂</mi><msub><mi>x</mi><mi>n</mi></msub><mi>∂</mi><msub><mi>x</mi><mn>1</mn></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mtd></mtr><mtr><mtd columnalign="center"><mfrac><mrow><msup><mi>∂</mi><mn>2</mn></msup><mi>f</mi></mrow><mrow><mi>∂</mi><msub><mi>x</mi><mn>1</mn></msub><mi>∂</mi><msub><mi>x</mi><mn>2</mn></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd><mfrac><mrow><msup><mi>∂</mi><mn>2</mn></msup><mi>f</mi></mrow><mrow><mi>∂</mi><msub><mi>x</mi><mn>2</mn></msub><mi>∂</mi><msub><mi>x</mi><mn>2</mn></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd><mi>…</mi></mtd><mtd><mfrac><mrow><msup><mi>∂</mi><mn>2</mn></msup><mi>f</mi></mrow><mrow><mi>∂</mi><msub><mi>x</mi><mi>n</mi></msub><mi>∂</mi><msub><mi>x</mi><mn>2</mn></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mtd></mtr><mtr><mtd columnalign="center"><mi>⋮</mi></mtd><mtd><mi>⋮</mi></mtd><mtd><mi>…</mi></mtd><mtd><mi>⋮</mi></mtd></mtr><mtr><mtd columnalign="center"><mfrac><mrow><msup><mi>∂</mi><mn>2</mn></msup><mi>f</mi></mrow><mrow><mi>∂</mi><msub><mi>x</mi><mn>1</mn></msub><mi>∂</mi><msub><mi>x</mi><mi>n</mi></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd><mfrac><mrow><msup><mi>∂</mi><mn>2</mn></msup><mi>f</mi></mrow><mrow><mi>∂</mi><msub><mi>x</mi><mn>2</mn></msub><mi>∂</mi><msub><mi>x</mi><mi>n</mi></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mtd><mtd><mi>…</mi></mtd><mtd><mfrac><mrow><msup><mi>∂</mi><mn>2</mn></msup><mi>f</mi></mrow><mrow><mi>∂</mi><msub><mi>x</mi><mi>n</mi></msub><mi>∂</mi><msub><mi>x</mi><mi>n</mi></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mtd></mtr></mtable><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">  H_f(x) = \left( \begin{array}{c} \frac{\partial^2 f}{\partial x_1 \partial x_1}(x)  &amp;  \frac{\partial^2 f}{\partial x_2 \partial x_1}(x) &amp; \dots &amp; \frac{\partial^2 f}{\partial x_n \partial x_1}(x) \\
                     \frac{\partial^2 f}{\partial x_1 \partial x_2}(x)  &amp;  \frac{\partial^2 f}{\partial x_2 \partial x_2}(x) &amp; \dots &amp; \frac{\partial^2 f}{\partial x_n \partial x_2}(x) \\
                     \vdots &amp; \vdots &amp; \dots &amp; \vdots \\
                     \frac{\partial^2 f}{\partial x_1 \partial x_n}(x)  &amp;  \frac{\partial^2 f}{\partial x_2 \partial x_n}(x) &amp; \dots &amp; \frac{\partial^2 f}{\partial x_n \partial x_n}(x) 
                     \end{array}
             \right)
</annotation></semantics></math></li>
</ul>
<h3 id="optimality-conditions">Optimality Conditions</h3>
<ul>
<li><strong>First Order Necessary Conditions</strong>: If <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> is continously differentiable and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>x</mi><mo>*</mo></msup><annotation encoding="application/x-tex">x^*</annotation></semantics></math> is a local minimizer of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>, then <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mo>*</mo></msup><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\nabla f(x^*) = 0</annotation></semantics></math>.</li>
<li><strong>Second Order Necessary Conditions</strong>: If <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> is twice continuously differentiable and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>x</mi><mo>*</mo></msup><annotation encoding="application/x-tex">x^*</annotation></semantics></math> is a local minimizer of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>, then <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mo>*</mo></msup><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\nabla f(x^*) = 0</annotation></semantics></math> <em>and</em> <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mi>f</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mo>*</mo></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">H_f (x^*)</annotation></semantics></math> is positive semi-definite, i.e. we have <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>s</mi><mi>T</mi></msup><msub><mi>H</mi><mi>f</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mo>*</mo></msup><mo stretchy="false" form="postfix">)</mo><mi>s</mi><mo>≥</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">s^T H_f (x^*) s \geq 0</annotation></semantics></math> for all <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>∈</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">s \in \mathbb{R}^n</annotation></semantics></math>.</li>
<li><strong>Second Order Sufficient Conditions</strong>: If <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> is twice continuously differentiable and at <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>x</mi><mo>*</mo></msup><annotation encoding="application/x-tex">x^*</annotation></semantics></math> we have that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mo>*</mo></msup><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\nabla f(x^*) = 0</annotation></semantics></math> <em>and</em> <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mi>f</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mo>*</mo></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">H_f (x^*)</annotation></semantics></math> is positive definite, i.e. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>s</mi><mi>T</mi></msup><msub><mi>H</mi><mi>f</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mo>*</mo></msup><mo stretchy="false" form="postfix">)</mo><mi>s</mi><mo>&gt;</mo><mn>0</mn><mo>,</mo><mi>s</mi><mo>≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">s^T H_f (x^*) s &gt; 0,s\neq 0</annotation></semantics></math> then <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>x</mi><mo>*</mo></msup><annotation encoding="application/x-tex">x^*</annotation></semantics></math> is a local minimizer of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>.</li>
<li>More sophisticated solvers make ample use of those.</li>
</ul>
</div>
<div id="reminder-sufficient-conditions-for-global-optimality" class="slide section level1">
<h1>Reminder: Sufficient Conditions for Global Optimality</h1>
<ul>
<li>If <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> is convex, then any local minimizer <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>x</mi><mo>*</mo></msup><annotation encoding="application/x-tex">x^*</annotation></semantics></math> is a global minimizer.</li>
<li>If <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> is convex and differentiable on <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup><annotation encoding="application/x-tex">\mathbb{R}^n</annotation></semantics></math> , then any point <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>x</mi><mo>*</mo></msup><annotation encoding="application/x-tex">x^*</annotation></semantics></math> is a global minimizer if and only if it is a stationary point, i.e. if f<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mo>*</mo></msup><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\nabla f(x^*) = 0</annotation></semantics></math>.</li>
</ul>
</div>
<div id="reminder-taylors-theorem" class="slide section level1">
<h1>Reminder: Taylor's Theorem</h1>
<ul>
<li>Many of the ensuing methods are based on Taylor's theorem, so let's remind ourselves of it:</li>
</ul>
<!--    f(x) & = & f(x^0) + \sum_{i=1}^n \frac{\partial f}{\partial x_i} (x^0) (x_i - x^0) \\
         & + & \frac{1}{2} + \sum_{i=1}^n \frac{\partial f}{\partial x_i} (x^0) (x_i - x^0) \\
 -->
<ul>
<li>Suppose that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>∈</mo><msup><mi>C</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msup><mo stretchy="false" form="prefix">[</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">f \in C^{n+1}[a,b]</annotation></semantics></math>, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>,</mo><msup><mi>x</mi><mn>0</mn></msup><mo>∈</mo><mo stretchy="false" form="prefix">[</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">x,x^0 \in [a,b]</annotation></semantics></math>. Then <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo></mtd><mtd columnalign="left"><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mn>0</mn></msup><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mi>f</mi><mi>′</mi><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mn>0</mn></msup><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>−</mo><msup><mi>x</mi><mn>0</mn></msup><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mi>f</mi><mi>″</mi><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mn>0</mn></msup><mo stretchy="false" form="postfix">)</mo><mfrac><mrow><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>−</mo><msup><mi>x</mi><mn>0</mn></msup><msup><mo stretchy="false" form="postfix">)</mo><mn>2</mn></msup></mrow><mn>2</mn></mfrac></mtd></mtr><mtr><mtd columnalign="right"><mo>+</mo></mtd><mtd columnalign="left"><mi>…</mi><mo>+</mo><msup><mi>f</mi><mrow><mo stretchy="false" form="prefix">(</mo><mi>n</mi><mo stretchy="false" form="postfix">)</mo></mrow></msup><mo stretchy="false" form="prefix">(</mo><msup><mi>x</mi><mn>0</mn></msup><mo stretchy="false" form="postfix">)</mo><mfrac><mrow><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>−</mo><msup><mi>x</mi><mn>0</mn></msup><msup><mo stretchy="false" form="postfix">)</mo><mi>n</mi></msup></mrow><mrow><mi>n</mi><mi>!</mi></mrow></mfrac><mo>+</mo><msub><mi>R</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mtd></mtr></mtable><annotation encoding="application/x-tex"> \begin{align}
f(x)  = &amp; f(x^0) + f&#39;(x^0)(x - x^0) + f&#39;&#39;(x^0)\frac{(x- x^0)^2}{2}\\
      + &amp; \dots + f^{(n)}(x^0)\frac{(x - x^0)^n}{n!} + R_{n+1}(x) 
     \end{align}
     </annotation></semantics></math> where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mstyle mathvariant="script"><mi>ℴ</mi></mstyle><mrow><mo stretchy="true" form="prefix">(</mo><mo stretchy="false" form="postfix">‖</mo><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>−</mo><msup><mi>x</mi><mn>0</mn></msup><mo stretchy="false" form="postfix">)</mo><msup><mo stretchy="false" form="postfix">‖</mo><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">R_{n+1}(x) = \mathcal{o}\left(\Vert (x-x^0) \Vert^{n+1}\right)</annotation></semantics></math> is reminder term that converges at a rate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n+1</annotation></semantics></math> to zero, i.e.</li>
<li>we say a function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> is <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>ℴ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mo stretchy="false" form="postfix">‖</mo><mi>x</mi><msup><mo stretchy="false" form="postfix">‖</mo><mi>n</mi></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{o}(\Vert x \Vert^n)</annotation></semantics></math> if <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>lim</mo><mrow><mi>x</mi><mo accent="false">→</mo><mn>0</mn></mrow></msub><mo stretchy="false" form="postfix">‖</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">‖</mo><mi>/</mi><mo stretchy="false" form="postfix">‖</mo><mi>x</mi><msup><mo stretchy="false" form="postfix">‖</mo><mi>n</mi></msup><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lim_{x\to 0}\Vert f(x) \Vert / \Vert x \Vert^n =0</annotation></semantics></math>.</li>
<li>we say a function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> is <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒪</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mo stretchy="false" form="postfix">‖</mo><mi>x</mi><msup><mo stretchy="false" form="postfix">‖</mo><mi>n</mi></msup><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(\Vert x \Vert^n)</annotation></semantics></math> if <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>lim</mo><mrow><mi>x</mi><mo accent="false">→</mo><mn>0</mn></mrow></msub><mo stretchy="false" form="postfix">‖</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">‖</mo><mi>/</mi><mo stretchy="false" form="postfix">‖</mo><mi>x</mi><msup><mo stretchy="false" form="postfix">‖</mo><mi>n</mi></msup><mo>&lt;</mo><mi>∞</mi></mrow><annotation encoding="application/x-tex">\lim_{x\to 0}\Vert f(x) \Vert / \Vert x \Vert^n &lt; \infty</annotation></semantics></math></li>
</ul>
</div>
<div id="a-quick-note-on-computing-derivatives" class="slide section level1">
<h1>A quick Note on Computing Derivatives</h1>
<ul>
<li>Finite Differences</li>
<li>Automatic Differentiation</li>
<li>We will talk about this in a separate session.</li>
<li>For now just remember that if we don't supply analytic gradients, and the algorithm requires them, this often triggers a numerical approximation of the gradient known as finite differences. This is most of the times a slow proceedure.</li>
</ul>
</div>
<div id="two-strategies-line-search-and-trust-region" class="slide section level1">
<h1>Two Strategies: Line Search and Trust Region</h1>
<ul>
<li>We only provide an overview of methods here. If you want to <em>really</em> know the details about those algorithms, I invite you to consult <span class="citation">(Nocedal and Wright 2006)</span>.</li>
</ul>
<h3 id="the-line-search-strategy">The Line Search Strategy</h3>
<ul>
<li>An algorithm from the line search class chooses a direction <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub><mo>∈</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">p_k \in \mathbb{R}^n</annotation></semantics></math> and searches along that direction starting from the current iterate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub><mo>∈</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">x_k \in \mathbb{R}^n</annotation></semantics></math> for a new iterate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>∈</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">x_{k+1} \in \mathbb{R}^n</annotation></semantics></math> with a lower function value.</li>
<li>After deciding on a direction <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>p</mi><mi>k</mi></msub><annotation encoding="application/x-tex">p_k</annotation></semantics></math>, one needs to decide the <em>step length</em> <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math> to travel by solving <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>min</mo><mrow><mi>α</mi><mo>&gt;</mo><mn>0</mn></mrow></munder><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo>+</mo><mi>α</mi><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex"> \min_{\alpha&gt;0} f(x_k + \alpha p_k) </annotation></semantics></math></li>
<li>In practice, solving this exactly is too costly, so algos usually generate a sequence of trial values <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math> and pick the one with the lowest <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>.</li>
</ul>
<h3 id="the-trust-region-strategy">The Trust Region Strategy</h3>
<ul>
<li>Here we construct a <em>model function</em> <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>m</mi><mi>k</mi></msub><annotation encoding="application/x-tex">m_k</annotation></semantics></math> that is similar to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> around <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>k</mi></msub><annotation encoding="application/x-tex">x_k</annotation></semantics></math>.</li>
<li>We acknowledge that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>m</mi><mi>k</mi></msub><annotation encoding="application/x-tex">m_k</annotation></semantics></math> is decent approximation of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> only in some <em>region</em>.</li>
<li>The problem is then to find a candidate step length <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math> by solving <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>min</mo><mi>p</mi></munder><msub><mi>m</mi><mi>k</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo>+</mo><mi>p</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex"> \min_p m_k (x_k + p) </annotation></semantics></math> where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub><mo>+</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">x_k + p</annotation></semantics></math> lies inside the trust region.</li>
<li>If candidate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math> does not produce a value lower than <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">f(x_k)</annotation></semantics></math>, we must have had a too large trust region, shrink it, and do it again.</li>
<li>Usually the trust region is a ball <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="postfix">‖</mo><mi>p</mi><msub><mo stretchy="false" form="postfix">‖</mo><mn>2</mn></msub><mo>≤</mo><mi>Δ</mi></mrow><annotation encoding="application/x-tex">\Vert p \Vert_2 \leq \Delta</annotation></semantics></math>, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Δ</mi><annotation encoding="application/x-tex">\Delta</annotation></semantics></math> is called the <em>trust region radius</em>, but elliptical and box regions are possible.</li>
<li>A common definition of the model function is a quadratic of the form <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>m</mi><mi>k</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo>+</mo><mi>p</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>+</mo><msup><mi>p</mi><mi>T</mi></msup><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msup><mi>p</mi><mi>T</mi></msup><mi>B</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><mi>p</mi></mrow><annotation encoding="application/x-tex"> m_k(x_k + p) = f(x_k) + p^T \nabla f(x_k) + \frac{1}{2} p^T B(x_k) p </annotation></semantics></math> where gradient and matrix <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">B(x_k)</annotation></semantics></math> are evaluated at the current iterate, so the model function is in agreement to first order with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> at the current guess.</li>
<li>The matrix <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">B(x_k)</annotation></semantics></math> is either the Hessian <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>f</mi></msub><annotation encoding="application/x-tex">H_f</annotation></semantics></math> or some approximation to it.</li>
</ul>
</div>
<div id="trust-region-example" class="slide section level1">
<h1>Trust Region Example</h1>
<ul>
<li>Suppose we have <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mn>10</mn><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo>−</mo><msubsup><mi>x</mi><mn>1</mn><mn>2</mn></msubsup><msup><mo stretchy="false" form="postfix">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>x</mi><mn>1</mn></msub><msup><mo stretchy="false" form="postfix">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">f(x) = 10(x_2 - x_1^2)^2 + (1-x_1)^2</annotation></semantics></math>. At point <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>k</mi></msub><mo>=</mo><mo stretchy="false" form="prefix">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">x_k= (0,1)</annotation></semantics></math> gradient and hessian are:</li>
<li>?</li>
</ul>
<div class="incremental">
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center"><mo>−</mo><mn>2</mn></mtd></mtr><mtr><mtd columnalign="center"><mn>20</mn></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow><mo>,</mo><mspace width="1.0em"></mspace><mspace width="1.0em"></mspace><msup><mi>∇</mi><mn>2</mn></msup><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center"><mo>−</mo><mn>38</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd columnalign="center"><mn>0</mn></mtd><mtd><mn>20</mn></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex"> \nabla f(x_k) = \left[ \begin{array}{c} -2 \\ 20 \end{array} \right], \quad \quad \nabla^2 f(x_k) = \left[ \begin{array}{c} -38 &amp; 0 \\ 0 &amp; 20 \end{array} \right] </annotation></semantics></math></p>
<div class="figure">
<img src="figs-restricted/trust-region.png" alt="Figure 2.4 of (Nocedal and Wright 2006)" />
<p class="caption">Figure 2.4 of <span class="citation">(Nocedal and Wright 2006)</span></p>
</div>
<ul>
<li>In this figure, we use <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><msup><mi>∇</mi><mn>2</mn></msup><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">B(x_k) = \nabla^2 f(x_k)</annotation></semantics></math>.</li>
<li>After each unsuccesful step, the new candidate step will be shorter, and will go in a different direction</li>
<li>This is the main difference to line search methods.</li>
<li>Main difference between the two methods: order in which they change <em>direction</em> and <em>step length</em>
<ul>
<li>line search fixes direction <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>p</mi><mi>k</mi></msub><annotation encoding="application/x-tex">p_k</annotation></semantics></math> and finds right distance <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\alpha_k</annotation></semantics></math></li>
<li>trust region fixes an appropriate radius <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Δ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\Delta_k</annotation></semantics></math></li>
</ul></li>
</ul>
</div>
</div>
<div id="line-search-methods-which-direction-to-go" class="slide section level1">
<h1>Line Search Methods: Which Direction to go?</h1>
<h3 id="steepest-descent">Steepest Descent</h3>
<ul>
<li>The direction <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">-\nabla f(x_k)</annotation></semantics></math> is an obvious choice: Among all possible directions, along this one <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> decreases most rapidly.</li>
<li>This claim can be verified using Taylor's theorem.</li>
<li>The <strong>steepest descent method</strong> is a line search method that moves along <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub><mo>=</mo><mo>−</mo><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex"> p_k = -\nabla f(x_k) </annotation></semantics></math></li>
<li>The step length <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\alpha_k</annotation></semantics></math> can be chosen in many different ways.</li>
<li>There are many other <em>descent</em> directions, steepest descent is but one of them.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia">optimize(rosenbrock, rosenbrock_gradient!, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :gradient_descent)
optimize(rosenbrock, rosenbrock_gradient!, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :gradient_descent,iterations=<span class="fl">5000</span>)
optimize(rosenbrock, rosenbrock_gradient!, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :gradient_descent,iterations=<span class="fl">10000</span>)</code></pre></div>
<div class="figure">
<img src="figs-restricted/steepest-descent.png" alt="Figure 2.5 of (Nocedal and Wright 2006)" />
<p class="caption">Figure 2.5 of <span class="citation">(Nocedal and Wright 2006)</span></p>
</div>
</div>
<div id="line-search-methods-the-newton-direction" class="slide section level1">
<h1>Line Search Methods: The <strong>Newton</strong> Direction</h1>
<ul>
<li>Probably the most important descent direction.</li>
<li>In vector notation, the 2nd order taylor series approximation to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo>+</mo><mi>p</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">f(x_k + p)</annotation></semantics></math> is <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo>+</mo><mi>p</mi><mo stretchy="false" form="postfix">)</mo><mo>≈</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>+</mo><msup><mi>p</mi><mi>T</mi></msup><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msup><mi>p</mi><mi>T</mi></msup><msup><mi>∇</mi><mn>2</mn></msup><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><mi>p</mi><mo>≡</mo><msub><mi>m</mi><mi>k</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>p</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex"> f(x_k + p) \approx f(x_k) + p^T \nabla f(x_k) + \frac{1}{2} p^T \nabla^2 f(x_k) p \equiv m_k(p) </annotation></semantics></math></li>
<li>the Newton direction is obtained by finding the vector <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math> that minimizes <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>m</mi><mi>k</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>p</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">m_k(p)</annotation></semantics></math>, i.e. by setting the derivative of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>m</mi><mi>k</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>p</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">m_k(p)</annotation></semantics></math> to zero.</li>
<li>We obtain <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>p</mi><mi>k</mi><mi>N</mi></msubsup><mo>=</mo><mo>−</mo><mo stretchy="false" form="prefix">(</mo><msup><mi>∇</mi><mn>2</mn></msup><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex"> p_k^N = -(\nabla^2 f(x_k))^{-1} \nabla f(x_k)  </annotation></semantics></math></li>
<li>The newton direction is reliable if the discrepancy between truth and model <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math> is not too large at <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>k</mi></msub><annotation encoding="application/x-tex">x_k</annotation></semantics></math>.</li>
<li>The biggest drawback is the need to compute the Hessian. This can be difficult analytically at times, and overly expensive numerically.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia">optimize(rosenbrock, rosenbrock_gradient!, rosenbrock_hessian!, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :newton)</code></pre></div>
</div>
<div id="quasi-newton-methods" class="slide section level1">
<h1>Quasi-Newton Methods</h1>
<ul>
<li>In response to the difficulties of getting the Hessian, quasi-newton methods propose to approximate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">B(x_k)</annotation></semantics></math> with something <em>similar</em> to the hessian.</li>
<li>Taylors Theorem implies that <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>∇</mi><mn>2</mn></msup><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>≈</mo><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>−</mo><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex"> \nabla^2 f(x_{k+1} - x_{k}) \approx \nabla f(x_{k+1}) - \nabla f(x_k) </annotation></semantics></math> and so we choose a <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math> matrix that mimics this property.</li>
<li>This leads to the <em>secant condition</em> <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>−</mo><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex"> B_{k+1} (x_{k+1} - x_{k}) = f(x_{k+1}) - \nabla f(x_k) </annotation></semantics></math></li>
<li>There are different ways to update the hessian in this way.</li>
<li>One of the best known is the BFGS method (after Broydon, Fletcher, Goldfarb and Shanno).</li>
<li>Those methods get the search direction by using <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>B</mi><mi>k</mi></msub><annotation encoding="application/x-tex">B_k</annotation></semantics></math> instead of the exact Hessian, i.e. <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub><mo>=</mo><mo>−</mo><msubsup><mi>B</mi><mi>k</mi><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><mi>∇</mi><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex"> p_k = -B_k^{-1} \nabla f(x_k)  </annotation></semantics></math></li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia">optimize(rosenbrock, rosenbrock_gradient!, rosenbrock_hessian!, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :bfgs)
<span class="co"># low memory BFGS</span>
optimize(rosenbrock, rosenbrock_gradient!, rosenbrock_hessian!, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :l_bfgs)</code></pre></div>
</div>
<div id="practical-considerations" class="slide section level1">
<h1>Practical Considerations</h1>
<h2 id="stopping-criteria">Stopping criteria</h2>
<ul>
<li>In all of the above examples, we did not alter the default values for stopping criteria.</li>
<li>There are different things you could focus on as a stopping criterion with <code>Optim</code>, and similarly in most solver packages.
<ul>
<li><code>xtol</code>: changes in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> from one iterate to the next</li>
<li><code>ftol</code>: perentage changes in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> from one iterate to the next</li>
<li><code>grtol</code>: absolute value of the gradient beign smaller than this number.</li>
</ul></li>
</ul>
</div>
<div id="some-applications-in-economics" class="slide section level1">
<h1>Some Applications in Economics</h1>
<ul>
<li>Maximum Likelihood Estimation</li>
<li>The Nested Fixed Point Algorithm
<ul>
<li><span class="citation">(Rust 1987)</span> is a maximum likelihood estimation with an inner loop that solves a dynamic programming problem.</li>
<li><span class="citation">(Berry et al. 1995)</span> is a GMM estimation with an inner fixed point problem.</li>
</ul></li>
</ul>
</div>
<div id="references" class="slide section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-BLP">
<p>Berry, S., Levinsohn, J., &amp; Pakes, A. (1995). Automobile prices in market equilibrium. <em>Econometrica: Journal of the Econometric Society</em>, 841–890.</p>
</div>
<div id="ref-nocedal-wright">
<p>Nocedal, J., &amp; Wright, S. (2006). <em>Numerical optimization</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-casella-R">
<p>Robert, C., &amp; Casella, G. (2009). <em>Introducing monte carlo methods with r</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-rust-bus">
<p>Rust, J. (1987). Optimal replacement of gmc bus engines: An empirical model of harold zurcher. <em>Econometrica</em>, <em>55</em>(5), 999–1033. <a href="http://www.jstor.org/stable/1911259" class="uri">http://www.jstor.org/stable/1911259</a></p>
</div>
</div>
</div>
</body>
</html>
