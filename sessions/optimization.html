<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Florian Oswald" />
  <title>Computational Economics: Unconstrained Optimization</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; background-color: #dddddd; }
td.sourceCode { padding-left: 5px; }
code > span.kw { font-weight: bold; } /* Keyword */
code > span.dt { color: #800000; } /* DataType */
code > span.dv { color: #0000ff; } /* DecVal */
code > span.bn { color: #0000ff; } /* BaseN */
code > span.fl { color: #800080; } /* Float */
code > span.ch { color: #ff00ff; } /* Char */
code > span.st { color: #dd0000; } /* String */
code > span.co { color: #808080; font-style: italic; } /* Comment */
code > span.al { color: #00ff00; font-weight: bold; } /* Alert */
code > span.fu { color: #000080; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #ff0000; font-weight: bold; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #ff00ff; } /* SpecialChar */
code > span.vs { color: #dd0000; } /* VerbatimString */
code > span.ss { color: #dd0000; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { } /* Variable */
code > span.cf { } /* ControlFlow */
code > span.op { } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { font-weight: bold; } /* Preprocessor */
code > span.at { } /* Attribute */
code > span.do { color: #808080; font-style: italic; } /* Documentation */
code > span.an { color: #808080; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #808080; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #808080; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="http://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <script src="http://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Computational Economics: Unconstrained Optimization</h1>
  <p class="author">
Florian Oswald
  </p>
  <p class="date">Sciences Po, 2016</p>
</div>
<div id="some-taxonomy-and-initial-examples" class="slide section level1">
<h1>Some Taxonomy and Initial Examples</h1>
<ul>
<li>In most of the examples to follow, we talk about <em>minimization</em> of a function <span class="math inline">\(f\)</span>. Everything we do also applies to maximization, since <span class="math inline">\(\min_x f(x) = \max_x -f(x)\)</span>.</li>
<li><p>Here is a generic optimization problem: <span class="math display">\[ \min_{x\in\mathbb{R}^n} f(x)  \quad  s.t.\quad \begin{array} c_i(x) = 0, &amp; i\in E \\
                                                          c_i(x) \geq 0, &amp; i\in I \end{array}
                                                          \]</span></p></li>
<li>This is a general way of writing an optimization problem. E are all indices as equality constraints, I are all inequality constraints.</li>
<li>An example of such a problem might be <span class="math display">\[ \min (x_1 -2)^2 + (x_2 -1)^2 \quad  s.t.\quad \begin{array} x_{1}^2 -x_2 \leq 0 \\
                                                          x_1 +x_2 \leq 2 \end{array}
                                                          \]</span></li>
<li><p>Here is a picture of that problem taken from the textbook <span class="citation">(Nocedal and Wright 2006)</span> ( for copyright reasons, I cannot show this in the online version of the slides. ):</p></li>
</ul>
<div class="figure">
<img src="figs-restricted/feasible-region.png" alt="Figure 1.1 in (Nocedal and Wright 2006)" />
<p class="caption">Figure 1.1 in <span class="citation">(Nocedal and Wright 2006)</span></p>
</div>
</div>
<div id="kinds-of-problems-considered" class="slide section level1">
<h1>Kinds of problems considered</h1>
<ul>
<li>Don't talk about stochastic optimization methods:
<ul>
<li>Simluated Annealing</li>
<li>MCMC</li>
<li>other Stochastic Search Methods</li>
<li>A gentle introduction is <span class="citation">(Robert and Casella 2009)</span></li>
</ul></li>
</ul>
</div>
<div id="transportation-problem" class="slide section level1">
<h1>Transportation Problem</h1>
<blockquote>
<p>A chemical company has two factories <span class="math inline">\(F_1,F_2\)</span> and a dozen retail outlets <span class="math inline">\(R_1,\dots,R_{12}\)</span>. Each factory <span class="math inline">\(i\)</span> can produce at most <span class="math inline">\(a_i\)</span> tons of output each week. Each retail outlet <span class="math inline">\(j\)</span> has a weekly demand of <span class="math inline">\(b_j\)</span> tons per week. The cost of shipping from <span class="math inline">\(F_i\)</span> to <span class="math inline">\(R_j\)</span> is given by <span class="math inline">\(c_{ij}\)</span>. How much of the product to ship from each factory to each outlet, minimize cost, and satisfy all constraints? let's call <span class="math inline">\(x_{ij}\)</span> the number of tons shipped from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span>.</p>
</blockquote>
<div class="figure">
<img src="figs-restricted/transportation.png" alt="Figure 1.2 in (Nocedal and Wright 2006)" />
<p class="caption">Figure 1.2 in <span class="citation">(Nocedal and Wright 2006)</span></p>
</div>
<div class="incremental">
<ul>
<li><p>A mathematical formulation of this problem is <span class="math display">\[ \begin{align}
    \min \sum_{ij} c_{ij} x_{ij} \\
    \text{subject to} \sum_{j=1}^{12} x_{ij} \leq a_i,\quad i=1,2 \\
    \sum_{i=1}^2  x_{ij} \geq b_j,\quad j=1,\dots,12  \\
    x_{ij} \geq 0, \quad i=1,2,j=1,\dots,12
    \end{align}
    \]</span></p></li>
<li>This is called a <em>linear programming</em> problem, because both objective function and all constrains are linear.</li>
<li><p>With any of those being nonlinear, we would call this a non-linear problem.</p></li>
</ul>
</div>
</div>
<div id="constrained-vs-unconstrained" class="slide section level1">
<h1>Constrained vs Unconstrained</h1>
<ul>
<li>There are many applications of both in economics.</li>
<li>Unconstrained: maximimum likelihood</li>
<li>Constrained: MPEC</li>
<li>It is sometimes possible to transform a constrained problem into an unconstrained one.</li>
</ul>
</div>
<div id="convexity" class="slide section level1">
<h1>Convexity</h1>
<ul>
<li>Convex problems are easier to solve.</li>
<li>What is convex?</li>
</ul>
<blockquote>
<p>A set <span class="math inline">\(S\in\mathbb{R}^n\)</span> is convex if the straight line segment connecting any two points in <span class="math inline">\(S\)</span> lies entirely inside <span class="math inline">\(S\)</span>. A function <span class="math inline">\(f\)</span> is a convex function, if its domain <span class="math inline">\(S\)</span> is a convex set, and for any two points <span class="math inline">\(x,y \in S\)</span>, we have that <span class="math display">\[ f(\alpha x + (1-\alpha)y) \leq \alpha f(x) + (1-\alpha) f(y) \]</span> for all <span class="math inline">\(\alpha \in [0,1]\)</span></p>
</blockquote>
<ul>
<li>Simple instances of convex sets are the unit ball <span class="math inline">\(\{y \in \mathbb{R}^n, \Vert y\Vert_2 \leq 1\}\)</span>, and any set defined by linear equalities and inequalities.</li>
<li><em>convex Programming</em> describes a special case of the introductory minimizatin problem where
<ul>
<li>the objective function is convex,</li>
<li>the equality constrains are linear, and</li>
<li>the inequality constraints are concave.</li>
</ul></li>
</ul>
</div>
<div id="optimization-algorithms" class="slide section level1">
<h1>Optimization Algorithms</h1>
<ul>
<li>All of the algorithms we are going to see employ some kind of <em>iterative</em> proceedure.</li>
<li>They try to improve the value of the objective function over successive steps.</li>
<li>The way the algorithm goes about generating the next step is what distinguishes algorithms from one another.
<ul>
<li>Some algos only use the objective function</li>
<li>Some use both objective and gradients</li>
<li>Some add the Hessian</li>
<li>and many variants more</li>
</ul></li>
</ul>
<div class="incremental">
<h2 id="desirable-features-of-any-algorithm">Desirable Features of any Algorithm</h2>
<ul>
<li>Robustness: We want good performance on a wide variety of problems in their class, and starting from <em>all</em> reasonable starting points.</li>
<li>Efficiency: They should be fast and not use an excessive amount of memory.</li>
<li>Accuracy: They should identify the solution with high precision.</li>
</ul>
<h2 id="a-word-of-caution">A Word of Caution</h2>
<ul>
<li>You should <strong>not</strong> normally attempt to write a numerical optimizer for yourself.</li>
<li>Entire generations of Applied Mathematicians and other numerical pro's have worked on those topics before you, so you should use their work.
<ul>
<li>Any optimizer you could come up with is probably going to perform below par, and be highly likely to contain mistakes.</li>
<li>Don't reinvent the wheel.</li>
</ul></li>
<li>That said, it's very important that we understand some basics about the main algorithms, because your task is <strong>to choose from the wide array of available ones</strong>.</li>
</ul>
</div>
</div>
<div id="unconstrained-optimization-what-is-a-solution" class="slide section level1">
<h1>Unconstrained Optimization: What is a solution?</h1>
<ul>
<li>A typical unconstrained optimization problem will look something like this: <span class="math display">\[ \min_x f(x),\quad x\in \mathbb{R}^n \]</span> and where <span class="math inline">\(f : \mathbb{R}^n \mapsto \mathbb{R}\)</span> is a smooth function.</li>
<li>In general, we would always like to find a <em>global</em> minimizer, i.e.
<div class="center" style="width: auto; margin-left: auto; margin-right: auto;">
a point <span class="math inline">\(x^*\)</span> where <span class="math inline">\(f(x^*) \leq f(x)\quad \forall x\)</span>
</div></li>
<li>Since our algorithm is not going to visit many points in <span class="math inline">\(\mathbb{R}^n\)</span> (or so we hope), we can never be totally sure that we find a global optimizer.</li>
<li>Most optimizers can only find a <em>local</em> minimizer. That is a point
<div class="center" style="width: auto; margin-left: auto; margin-right: auto;">
<span class="math inline">\(x^*\)</span> where <span class="math inline">\(f(x^*) \leq f(x)\quad \forall x \in \mathcal{N}\)</span> where <span class="math inline">\(\mathcal{N}\)</span> is a neighborhood around <span class="math inline">\(x^*\)</span>.
</div></li>
<li>Global minization can be very hard sometimes.</li>
</ul>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Eggholder_function.pdf/page1-800px-Eggholder_function.pdf.jpg" alt="Global min at f(512, 404.2319). By Gaortizg GFDL or CC BY-SA 3.0, via Wikimedia Commons" />
<p class="caption">Global min at <span class="math inline">\(f(512, 404.2319)\)</span>. By Gaortizg <a href="http://www.gnu.org/copyleft/fdl.html">GFDL</a> or <a href="http://creativecommons.org/licenses/by-sa/3.0">CC BY-SA 3.0</a>, via Wikimedia Commons</p>
</div>
</div>
<div id="unconstrained-optimization-in-julia" class="slide section level1">
<h1>(Unconstrained) Optimization in <code>Julia</code></h1>
<ul>
<li>Umbrella Organisation: <a href="http://www.juliaopt.org"><code>http://www.juliaopt.org</code></a>
<ul>
<li>We will make ample use of this when we talk about constrained optimsation.</li>
<li>The Julia Interface to the very well established <a href="http://ab-initio.mit.edu/wiki/index.php/NLopt">C-Library NLopt</a> is called <a href="https://github.com/JuliaOpt/NLopt.jl"><code>NLopt.jl</code></a>. One could use <code>NLopt</code> without constraints in an unconstrained problem.</li>
</ul></li>
<li><a href="https://github.com/JuliaLang/Roots.jl"><code>Roots.jl</code></a>: Simple algorithms that find the zeros of a univariate function.</li>
<li>Baseline Collection of unconstrained optimization algorithms: <a href="https://github.com/JuliaOpt/Optim.jl"><code>Optim.jl</code></a></li>
</ul>
</div>
<div id="introducing-optim.jl" class="slide section level1">
<h1>Introducing <a href="https://github.com/JuliaOpt/Optim.jl"><code>Optim.jl</code></a></h1>
<ul>
<li>Multipurpose unconstrained optimization package
<ul>
<li>provides 8 different algorithms</li>
<li>univariate optimization without derivatives</li>
</ul></li>
</ul>
<h3 id="introducing-rosenbrocks-banana-function">Introducing <a href="https://en.wikipedia.org/wiki/Rosenbrock_function">Rosenbrock's Banana</a> function</h3>
<p>The Banana function is defined by <span class="math display">\[ f(x,y) = (a-x)^2  + b(y-x^2)^2  \]</span></p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/3/32/Rosenbrock_function.svg" alt="Banana for a = 0. By Gaortizg GFDL or CC BY-SA 3.0, via Wikimedia Commons" />
<p class="caption">Banana for <span class="math inline">\(a = 0\)</span>. By Gaortizg <a href="http://www.gnu.org/copyleft/fdl.html">GFDL</a> or <a href="http://creativecommons.org/licenses/by-sa/3.0">CC BY-SA 3.0</a>, via Wikimedia Commons</p>
</div>
<h3 id="what-is-the-minimum-of-that-function">What is the minimum of that function?</h3>
<ul>
<li>For <span class="math inline">\(a=1,b=100\)</span>, what is the global minimum of that function?</li>
<li>What are the inputs one needs to supply to an algorithm in a more general example?</li>
</ul>
</div>
<div id="rosenbrock-banana-and-optim.jl" class="slide section level1">
<h1>Rosenbrock Banana and Optim.jl</h1>
<ul>
<li>We will use <code>Optim</code> for the rest of this lecture.</li>
<li>We need to supply the objective function and - depending on the solution algorithm - the gradient and hessian as well.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia"><span class="kw">function</span> rosenbrock(x::<span class="dt">Vector</span>)
    <span class="kw">return</span> (<span class="fl">1.0</span> - x[<span class="fl">1</span>])^<span class="fl">2</span> + <span class="fl">100.0</span> * (x[<span class="fl">2</span>] - x[<span class="fl">1</span>]^<span class="fl">2</span>)^<span class="fl">2</span>
<span class="kw">end</span>

<span class="kw">function</span> rosenbrock_gradient!(x::<span class="dt">Vector</span>, storage::<span class="dt">Vector</span>)
    storage[<span class="fl">1</span>] = -<span class="fl">2.0</span> * (<span class="fl">1.0</span> - x[<span class="fl">1</span>]) - <span class="fl">400.0</span> * (x[<span class="fl">2</span>] - x[<span class="fl">1</span>]^<span class="fl">2</span>) * x[<span class="fl">1</span>]
    storage[<span class="fl">2</span>] = <span class="fl">200.0</span> * (x[<span class="fl">2</span>] - x[<span class="fl">1</span>]^<span class="fl">2</span>)
<span class="kw">end</span>

<span class="kw">function</span> rosenbrock_hessian!(x::<span class="dt">Vector</span>, storage::<span class="dt">Matrix</span>)
    storage[<span class="fl">1</span>, <span class="fl">1</span>] = <span class="fl">2.0</span> - <span class="fl">400.0</span> * x[<span class="fl">2</span>] + <span class="fl">1200.0</span> * x[<span class="fl">1</span>]^<span class="fl">2</span>
    storage[<span class="fl">1</span>, <span class="fl">2</span>] = -<span class="fl">400.0</span> * x[<span class="fl">1</span>]
    storage[<span class="fl">2</span>, <span class="fl">1</span>] = -<span class="fl">400.0</span> * x[<span class="fl">1</span>]
    storage[<span class="fl">2</span>, <span class="fl">2</span>] = <span class="fl">200.0</span>
<span class="kw">end</span></code></pre></div>
</div>
<div id="comparison-methods" class="slide section level1">
<h1>Comparison Methods</h1>
<ul>
<li>We will now look at a first class of algorithms, which are very simple, but sometimes a good starting point.</li>
<li>They just <em>compare</em> function values.</li>
<li><em>Grid Search</em> : Compute the objective function at <span class="math inline">\(G=\{x_1,\dots,x_N\}\)</span> and pick the highest value of <span class="math inline">\(f\)</span>.
<ul>
<li>This is very slow.</li>
<li>It requires large <span class="math inline">\(N\)</span>.</li>
<li>But it's robust (will find global optimizer for large enough <span class="math inline">\(N\)</span>)</li>
</ul></li>
</ul>
<div class="incremental">
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia"><span class="co"># grid search on rosenbrock</span>
grid = collect(-<span class="fl">1.0</span>:<span class="fl">0.1</span>:<span class="fl">3</span>);
grid2D = [[i;j] <span class="kw">for</span> i <span class="kw">in</span> grid,j <span class="kw">in</span> grid];
val2D = map(rosenbrock,grid2D);
r = findmin(val2D);
println(<span class="st">&quot;grid search results in minimizer = $(grid2D[r[2]])&quot;</span>)</code></pre></div>
</div>
</div>
<div id="the-golden-ratio-or-bracketing-search-for-1d-problems" class="slide section level1">
<h1>The Golden Ratio or Bracketing Search for 1D problems</h1>
<ul>
<li>A derivative-free method</li>
<li>a Bracketing method
<ul>
<li>find the local minimum of <span class="math inline">\(f\)</span> on <span class="math inline">\([a,b]\)</span></li>
<li>select 2 interior points <span class="math inline">\(c,d\)</span> such that <span class="math inline">\(a&lt;c&lt;d&lt;b\)</span>
<ul>
<li><span class="math inline">\(f(c) \leq f(d) \implies\)</span> min must lie in <span class="math inline">\([a,d]\)</span>. replace <span class="math inline">\(b\)</span> with <span class="math inline">\(d\)</span>, start again with <span class="math inline">\([a,d]\)</span></li>
<li><span class="math inline">\(f(c) &gt; f(d) \implies\)</span> min must lie in <span class="math inline">\([c,b]\)</span>. replace <span class="math inline">\(a\)</span> with <span class="math inline">\(c\)</span>, start again with <span class="math inline">\([c,b]\)</span></li>
</ul></li>
<li>how to choose <span class="math inline">\(b,d\)</span> though?</li>
<li>we want the length of the interval to be independent of whether we replace upper or lower bound</li>
<li>we want to reuse the non-replaced point from the previous iteration.</li>
<li>these imply the golden rule:</li>
<li>new point <span class="math inline">\(x_i = a + \alpha_i (b-a)\)</span>, where <span class="math inline">\(\alpha_1 = \frac{3-\sqrt{5}}{2},\alpha_2=\frac{\sqrt{5}-1}{2}\)</span></li>
<li><span class="math inline">\(\alpha_2\)</span> is known as the <em>golden ratio</em>, well known for it's role in renaissance art.</li>
</ul></li>
</ul>
<h3 id="bracketing-search-in-julia">Bracketing Search in Julia</h3>
<ul>
<li>The package <a href="https://github.com/JuliaOpt/Optim.jl"><code>Optim.jl</code></a> provides an implementation of &quot;Brent's Method&quot; as well as the golden section search:</li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia">using Optim
using Gadfly
f(x) = exp(x) - x^<span class="fl">4</span>
minf(x) = -f(x)
plot(f,<span class="fl">0</span>,<span class="fl">2</span>)
brent = optimize(minf,<span class="fl">0</span>,<span class="fl">2</span>,method=:brent)
golden = optimize(minf,<span class="fl">0</span>,<span class="fl">2</span>,method=:golden_section)</code></pre></div>
<ul>
<li>how well does this do with many local minima?</li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia">g(x) = exp(x) - x^<span class="fl">4</span> +sin(<span class="fl">40</span>*x)
ming(x) = -g(x)
plot(g,<span class="fl">0</span>,<span class="fl">2</span>)
grid = collect(<span class="fl">0</span>:<span class="fl">0.0001</span>:<span class="fl">2</span>);
v,idx  = findmax(<span class="dt">Float64</span>[g(x) <span class="kw">for</span> x <span class="kw">in</span> grid])
println(<span class="st">&quot;grid maximizer is $(grid[idx])&quot;</span>)
golden = optimize(ming,<span class="fl">0</span>,<span class="fl">2</span>,method=:golden_section)
brent = optimize(ming,<span class="fl">0</span>,<span class="fl">2</span>,method=:brent)
using Base.Test
@test_approx_eq  grid[idx] golden.minimum
@test_approx_eq  grid[idx] brent.minimum</code></pre></div>
<ul>
<li>Not <em>very</em> well at all. You can easily see that this method only works for unimodal functions.</li>
<li>We get trapped in a local minimum here.</li>
</ul>
</div>
<div id="bracketing-for-multidimensional-problems-nelder-mead" class="slide section level1">
<h1>Bracketing for Multidimensional Problems: Nelder-Mead</h1>
<ul>
<li>The Goal here is to find the simplex containing the local minimizer <span class="math inline">\(x^*\)</span></li>
<li>In the case where <span class="math inline">\(f\)</span> is n-D, this simplex has <span class="math inline">\(n+1\)</span> vertices</li>
<li>In the case where <span class="math inline">\(f\)</span> is 2-D, this simplex has <span class="math inline">\(2+1\)</span> vertices, i.e. it's a triangle.</li>
<li>The method proceeds by evaluating the function at all <span class="math inline">\(n+1\)</span> vertices, and by replacing the worst function value with a new guess.</li>
<li>this can be achieved by a sequence of moves:
<ul>
<li>reflect</li>
<li>expand</li>
<li>contract</li>
<li>shrink movements.</li>
</ul></li>
</ul>
<div class="center" style="width: auto; margin-left: auto; margin-right: auto;">
<img src="figs/neldermeadsteps.gif" />
</div>
<ul>
<li>this is a very popular method. The matlab functions <code>fmincon</code> and <code>fminsearch</code> implements it.</li>
<li>When it works, it works quite fast.</li>
<li>No derivatives required.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia">using Optim
optimize(rosenbrock, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :nelder_mead)</code></pre></div>
<ul>
<li>But.</li>
</ul>
</div>
<div id="bracketing-for-multidimensional-problems-comment-on-nelder-mead" class="slide section level1">
<h1>Bracketing for Multidimensional Problems: Comment on Nelder-Mead</h1>
<blockquote>
<p>Lagarias et al. (SIOPT, 1999): At present there is no function in any dimension greater than one, for which the original Nelder-Mead algorithm has been proved to converge to a minimizer.</p>
</blockquote>
<blockquote>
<p>Given all the known inefficiencies and failures of the Nelder-Mead algorithm [...], one might wonder why it is used at all, let alone why it is so extraordinarily popular.</p>
</blockquote>
</div>
<div id="reminder-optimality-conditions" class="slide section level1">
<h1>Reminder: Optimality Conditions</h1>
<h3 id="notation">Notation</h3>
<ul>
<li>Unless otherwise noted, we have <span class="math inline">\(x \in \mathbb{R}^n\)</span> as an <span class="math inline">\(n\)</span> element vector.</li>
<li>The <strong>gradient</strong> of a function <span class="math inline">\(f : \mathbb{R}^n \mapsto \mathbb{R}\)</span> is denoted <span class="math inline">\(\nabla f:\mathbb{R}^n \mapsto \mathbb{R}^n\)</span> a it returns a vector <span class="math display">\[ \nabla f(x) = \left(\frac{\partial f}{\partial x_1}(x),\frac{\partial f}{\partial x_2}(x),\dots,\frac{\partial f}{\partial x_n}(x) \right) \]</span></li>
<li>It's <strong>hessian</strong> is a function denoted <span class="math inline">\(\nabla^2 f(x)\)</span> or <span class="math inline">\(H_f :\mathbb{R}^n \mapsto \mathbb{R}^{n\times n}\)</span> and returns an <span class="math inline">\((n,n)\)</span> matrix given by <span class="math display">\[  H_f(x) = \left( \begin{array}{c} \frac{\partial^2 f}{\partial x_1 \partial x_1}(x)  &amp;  \frac{\partial^2 f}{\partial x_2 \partial x_1}(x) &amp; \dots &amp; \frac{\partial^2 f}{\partial x_n \partial x_1}(x) \\
                     \frac{\partial^2 f}{\partial x_1 \partial x_2}(x)  &amp;  \frac{\partial^2 f}{\partial x_2 \partial x_2}(x) &amp; \dots &amp; \frac{\partial^2 f}{\partial x_n \partial x_2}(x) \\
                     \vdots &amp; \vdots &amp; \dots &amp; \vdots \\
                     \frac{\partial^2 f}{\partial x_1 \partial x_n}(x)  &amp;  \frac{\partial^2 f}{\partial x_2 \partial x_n}(x) &amp; \dots &amp; \frac{\partial^2 f}{\partial x_n \partial x_n}(x) 
                     \end{array}
             \right)
\]</span></li>
</ul>
<h3 id="optimality-conditions">Optimality Conditions</h3>
<ul>
<li><strong>First Order Necessary Conditions</strong>: If <span class="math inline">\(f\)</span> is continously differentiable and <span class="math inline">\(x^*\)</span> is a local minimizer of <span class="math inline">\(f\)</span>, then <span class="math inline">\(\nabla f(x^*) = 0\)</span>.</li>
<li><strong>Second Order Necessary Conditions</strong>: If <span class="math inline">\(f\)</span> is twice continuously differentiable and <span class="math inline">\(x^*\)</span> is a local minimizer of <span class="math inline">\(f\)</span>, then <span class="math inline">\(\nabla f(x^*) = 0\)</span> <em>and</em> <span class="math inline">\(H_f (x^*)\)</span> is positive semi-definite, i.e. we have <span class="math inline">\(s^T H_f (x^*) s \geq 0\)</span> for all <span class="math inline">\(s \in \mathbb{R}^n\)</span>.</li>
<li><strong>Second Order Sufficient Conditions</strong>: If <span class="math inline">\(f\)</span> is twice continuously differentiable and at <span class="math inline">\(x^*\)</span> we have that <span class="math inline">\(\nabla f(x^*) = 0\)</span> <em>and</em> <span class="math inline">\(H_f (x^*)\)</span> is positive definite, i.e. <span class="math inline">\(s^T H_f (x^*) s &gt; 0,s\neq 0\)</span> then <span class="math inline">\(x^*\)</span> is a local minimizer of <span class="math inline">\(f\)</span>.</li>
<li>More sophisticated solvers make ample use of those.</li>
</ul>
</div>
<div id="reminder-sufficient-conditions-for-global-optimality" class="slide section level1">
<h1>Reminder: Sufficient Conditions for Global Optimality</h1>
<ul>
<li>If <span class="math inline">\(f\)</span> is convex, then any local minimizer <span class="math inline">\(x^*\)</span> is a global minimizer.</li>
<li>If <span class="math inline">\(f\)</span> is convex and differentiable on <span class="math inline">\(\mathbb{R}^n\)</span> , then any point <span class="math inline">\(x^*\)</span> is a global minimizer if and only if it is a stationary point, i.e. if f<span class="math inline">\(\nabla f(x^*) = 0\)</span>.</li>
</ul>
</div>
<div id="reminder-taylors-theorem" class="slide section level1">
<h1>Reminder: Taylor's Theorem</h1>
<ul>
<li>Many of the ensuing methods are based on Taylor's theorem, so let's remind ourselves of it:</li>
</ul>
<!--    f(x) & = & f(x^0) + \sum_{i=1}^n \frac{\partial f}{\partial x_i} (x^0) (x_i - x^0) \\
         & + & \frac{1}{2} + \sum_{i=1}^n \frac{\partial f}{\partial x_i} (x^0) (x_i - x^0) \\
 -->
<ul>
<li>Suppose that <span class="math inline">\(f \in C^{n+1}[a,b]\)</span>, and <span class="math inline">\(x,x^0 \in [a,b]\)</span>. Then <span class="math display">\[ \begin{align}
f(x)  = &amp; f(x^0) + f&#39;(x^0)(x - x^0) + f&#39;&#39;(x^0)\frac{(x- x^0)^2}{2}\\
      + &amp; \dots + f^{(n)}(x^0)\frac{(x - x^0)^n}{n!} + R_{n+1}(x) 
     \end{align}
     \]</span> where <span class="math inline">\(R_{n+1}(x) = \mathcal{o}\left(\Vert (x-x^0) \Vert^{n+1}\right)\)</span> is reminder term that converges at a rate <span class="math inline">\(n+1\)</span> to zero, i.e.</li>
<li>we say a function <span class="math inline">\(f\)</span> is <span class="math inline">\(\mathcal{o}(\Vert x \Vert^n)\)</span> if <span class="math inline">\(\lim_{x\to 0}\Vert f(x) \Vert / \Vert x \Vert^n =0\)</span>.</li>
<li>we say a function <span class="math inline">\(f\)</span> is <span class="math inline">\(\mathcal{O}(\Vert x \Vert^n)\)</span> if <span class="math inline">\(\lim_{x\to 0}\Vert f(x) \Vert / \Vert x \Vert^n &lt; \infty\)</span></li>
</ul>
</div>
<div id="a-quick-note-on-computing-derivatives" class="slide section level1">
<h1>A quick Note on Computing Derivatives</h1>
<ul>
<li>Finite Differences</li>
<li>Automatic Differentiation</li>
<li>We will talk about this in a separate session.</li>
<li>For now just remember that if we don't supply analytic gradients, and the algorithm requires them, this often triggers a numerical approximation of the gradient known as finite differences. This is most of the times a slow proceedure.</li>
</ul>
</div>
<div id="two-strategies-line-search-and-trust-region" class="slide section level1">
<h1>Two Strategies: Line Search and Trust Region</h1>
<ul>
<li>We only provide an overview of methods here. If you want to <em>really</em> know the details about those algorithms, I invite you to consult <span class="citation">(Nocedal and Wright 2006)</span>.</li>
</ul>
<h3 id="the-line-search-strategy">The Line Search Strategy</h3>
<ul>
<li>An algorithm from the line search class chooses a direction <span class="math inline">\(p_k \in \mathbb{R}^n\)</span> and searches along that direction starting from the current iterate <span class="math inline">\(x_k \in \mathbb{R}^n\)</span> for a new iterate <span class="math inline">\(x_{k+1} \in \mathbb{R}^n\)</span> with a lower function value.</li>
<li>After deciding on a direction <span class="math inline">\(p_k\)</span>, one needs to decide the <em>step length</em> <span class="math inline">\(\alpha\)</span> to travel by solving <span class="math display">\[ \min_{\alpha&gt;0} f(x_k + \alpha p_k) \]</span></li>
<li>In practice, solving this exactly is too costly, so algos usually generate a sequence of trial values <span class="math inline">\(\alpha\)</span> and pick the one with the lowest <span class="math inline">\(f\)</span>.</li>
</ul>
<h3 id="the-trust-region-strategy">The Trust Region Strategy</h3>
<ul>
<li>Here we construct a <em>model function</em> <span class="math inline">\(m_k\)</span> that is similar to <span class="math inline">\(f\)</span> around <span class="math inline">\(x_k\)</span>.</li>
<li>We acknowledge that <span class="math inline">\(m_k\)</span> is decent approximation of <span class="math inline">\(f\)</span> only in some <em>region</em>.</li>
<li>The problem is then to find a candidate step length <span class="math inline">\(p\)</span> by solving <span class="math display">\[ \min_p m_k (x_k + p) \]</span> where <span class="math inline">\(x_k + p\)</span> lies inside the trust region.</li>
<li>If candidate <span class="math inline">\(p\)</span> does not produce a value lower than <span class="math inline">\(f(x_k)\)</span>, we must have had a too large trust region, shrink it, and do it again.</li>
<li>Usually the trust region is a ball <span class="math inline">\(\Vert p \Vert_2 \leq \Delta\)</span>, where <span class="math inline">\(\Delta\)</span> is called the <em>trust region radius</em>, but elliptical and box regions are possible.</li>
<li>A common definition of the model function is a quadratic of the form <span class="math display">\[ m_k(x_k + p) = f(x_k) + p^T \nabla f(x_k) + \frac{1}{2} p^T B(x_k) p \]</span> where gradient and matrix <span class="math inline">\(B(x_k)\)</span> are evaluated at the current iterate, so the model function is in agreement to first order with <span class="math inline">\(f\)</span> at the current guess.</li>
<li>The matrix <span class="math inline">\(B(x_k)\)</span> is either the Hessian <span class="math inline">\(H_f\)</span> or some approximation to it.</li>
</ul>
</div>
<div id="trust-region-example" class="slide section level1">
<h1>Trust Region Example</h1>
<ul>
<li>Suppose we have <span class="math inline">\(f(x) = 10(x_2 - x_1^2)^2 + (1-x_1)^2\)</span>. At point <span class="math inline">\(x_k= (0,1)\)</span> gradient and hessian are:</li>
<li>?</li>
</ul>
<div class="incremental">
<p><span class="math display">\[ \nabla f(x_k) = \left[ \begin{array}{c} -2 \\ 20 \end{array} \right], \quad \quad \nabla^2 f(x_k) = \left[ \begin{array}{c} -38 &amp; 0 \\ 0 &amp; 20 \end{array} \right] \]</span></p>
<div class="figure">
<img src="figs-restricted/trust-region.png" alt="Figure 2.4 of (Nocedal and Wright 2006)" />
<p class="caption">Figure 2.4 of <span class="citation">(Nocedal and Wright 2006)</span></p>
</div>
<ul>
<li>In this figure, we use <span class="math inline">\(B(x_k) = \nabla^2 f(x_k)\)</span>.</li>
<li>After each unsuccesful step, the new candidate step will be shorter, and will go in a different direction</li>
<li>This is the main difference to line search methods.</li>
<li>Main difference between the two methods: order in which they change <em>direction</em> and <em>step length</em>
<ul>
<li>line search fixes direction <span class="math inline">\(p_k\)</span> and finds right distance <span class="math inline">\(\alpha_k\)</span></li>
<li>trust region fixes an appropriate radius <span class="math inline">\(\Delta_k\)</span></li>
</ul></li>
</ul>
</div>
</div>
<div id="line-search-methods-which-direction-to-go" class="slide section level1">
<h1>Line Search Methods: Which Direction to go?</h1>
<h3 id="steepest-descent">Steepest Descent</h3>
<ul>
<li>The direction <span class="math inline">\(-\nabla f(x_k)\)</span> is an obvious choice: Among all possible directions, along this one <span class="math inline">\(f\)</span> decreases most rapidly.</li>
<li>This claim can be verified using Taylor's theorem.</li>
<li>The <strong>steepest descent method</strong> is a line search method that moves along <span class="math display">\[ p_k = -\nabla f(x_k) \]</span></li>
<li>The step length <span class="math inline">\(\alpha_k\)</span> can be chosen in many different ways.</li>
<li>There are many other <em>descent</em> directions, steepest descent is but one of them.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia">optimize(rosenbrock, rosenbrock_gradient!, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :gradient_descent)
optimize(rosenbrock, rosenbrock_gradient!, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :gradient_descent,iterations=<span class="fl">5000</span>)
optimize(rosenbrock, rosenbrock_gradient!, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :gradient_descent,iterations=<span class="fl">10000</span>)</code></pre></div>
<div class="figure">
<img src="figs-restricted/steepest-descent.png" alt="Figure 2.5 of (Nocedal and Wright 2006)" />
<p class="caption">Figure 2.5 of <span class="citation">(Nocedal and Wright 2006)</span></p>
</div>
</div>
<div id="line-search-methods-the-newton-direction" class="slide section level1">
<h1>Line Search Methods: The <strong>Newton</strong> Direction</h1>
<ul>
<li>Probably the most important descent direction.</li>
<li>In vector notation, the 2nd order taylor series approximation to <span class="math inline">\(f(x_k + p)\)</span> is <span class="math display">\[ f(x_k + p) \approx f(x_k) + p^T \nabla f(x_k) + \frac{1}{2} p^T \nabla^2 f(x_k) p \equiv m_k(p) \]</span></li>
<li>the Newton direction is obtained by finding the vector <span class="math inline">\(p\)</span> that minimizes <span class="math inline">\(m_k(p)\)</span>, i.e. by setting the derivative of <span class="math inline">\(m_k(p)\)</span> to zero.</li>
<li>We obtain <span class="math display">\[ p_k^N = -(\nabla^2 f(x_k))^{-1} \nabla f(x_k)  \]</span></li>
<li>The newton direction is reliable if the discrepancy between truth and model <span class="math inline">\(m\)</span> is not too large at <span class="math inline">\(x_k\)</span>.</li>
<li>The biggest drawback is the need to compute the Hessian. This can be difficult analytically at times, and overly expensive numerically.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia">optimize(rosenbrock, rosenbrock_gradient!, rosenbrock_hessian!, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :newton)</code></pre></div>
</div>
<div id="quasi-newton-methods" class="slide section level1">
<h1>Quasi-Newton Methods</h1>
<ul>
<li>In response to the difficulties of getting the Hessian, quasi-newton methods propose to approximate <span class="math inline">\(B(x_k)\)</span> with something <em>similar</em> to the hessian.</li>
<li>Taylors Theorem implies that <span class="math display">\[ \nabla^2 f(x_{k+1} - x_{k}) \approx \nabla f(x_{k+1}) - \nabla f(x_k) \]</span> and so we choose a <span class="math inline">\(B\)</span> matrix that mimics this property.</li>
<li>This leads to the <em>secant condition</em> <span class="math display">\[ B_{k+1} (x_{k+1} - x_{k}) = f(x_{k+1}) - \nabla f(x_k) \]</span></li>
<li>There are different ways to update the hessian in this way.</li>
<li>One of the best known is the BFGS method (after Broydon, Fletcher, Goldfarb and Shanno).</li>
<li>Those methods get the search direction by using <span class="math inline">\(B_k\)</span> instead of the exact Hessian, i.e. <span class="math display">\[ p_k = -B_k^{-1} \nabla f(x_k)  \]</span></li>
</ul>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia">optimize(rosenbrock, rosenbrock_gradient!, rosenbrock_hessian!, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :bfgs)
<span class="co"># low memory BFGS</span>
optimize(rosenbrock, rosenbrock_gradient!, rosenbrock_hessian!, [<span class="fl">0.0</span>, <span class="fl">0.0</span>], method = :l_bfgs)</code></pre></div>
</div>
<div id="practical-considerations" class="slide section level1">
<h1>Practical Considerations</h1>
<h2 id="stopping-criteria">Stopping criteria</h2>
<ul>
<li>In all of the above examples, we did not alter the default values for stopping criteria.</li>
<li>There are different things you could focus on as a stopping criterion with <code>Optim</code>, and similarly in most solver packages.
<ul>
<li><code>xtol</code>: changes in <span class="math inline">\(x\)</span> from one iterate to the next</li>
<li><code>ftol</code>: perentage changes in <span class="math inline">\(f\)</span> from one iterate to the next</li>
<li><code>grtol</code>: absolute value of the gradient beign smaller than this number.</li>
</ul></li>
</ul>
</div>
<div id="some-applications-in-economics" class="slide section level1">
<h1>Some Applications in Economics</h1>
<ul>
<li>Maximum Likelihood Estimation</li>
<li>The Nested Fixed Point Algorithm
<ul>
<li><span class="citation">(Rust 1987)</span> is a maximum likelihood estimation with an inner loop that solves a dynamic programming problem.</li>
<li><span class="citation">(Berry et al. 1995)</span> is a GMM estimation with an inner fixed point problem.</li>
</ul></li>
</ul>
</div>
<div id="references" class="slide section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-BLP">
<p>Berry, S., Levinsohn, J., &amp; Pakes, A. (1995). Automobile prices in market equilibrium. <em>Econometrica: Journal of the Econometric Society</em>, 841–890.</p>
</div>
<div id="ref-nocedal-wright">
<p>Nocedal, J., &amp; Wright, S. (2006). <em>Numerical optimization</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-casella-R">
<p>Robert, C., &amp; Casella, G. (2009). <em>Introducing monte carlo methods with r</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-rust-bus">
<p>Rust, J. (1987). Optimal replacement of gmc bus engines: An empirical model of harold zurcher. <em>Econometrica</em>, <em>55</em>(5), 999–1033. <a href="http://www.jstor.org/stable/1911259" class="uri">http://www.jstor.org/stable/1911259</a></p>
</div>
</div>
</div>
</body>
</html>
