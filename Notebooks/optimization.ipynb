{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% Computational Economics: Unconstrained Optimization\n",
    "% Florian Oswald\n",
    "% Sciences Po, 2016\n",
    "\n",
    "\n",
    "# Some Taxonomy and Initial Examples\n",
    "\n",
    "* In most of the examples to follow, we talk about *minimization* of a function $f$. Everything we do also applies to maximization, since $\\min_x f(x) = \\max_x -f(x)$.\n",
    "* Here is a generic optimization problem:\n",
    "\t$$ \\min_{x\\in\\mathbb{R}^n} f(x)  \\quad  s.t.\\quad \\begin{array} c_i(x) = 0, & i\\in E \\\\\n",
    "                                                              c_i(x) \\geq 0, & i\\in I \\end{array}\n",
    "                                                              $$\n",
    "\n",
    "* This is a general way of writing an optimization problem. E are all indices as equality constraints, I are all inequality constraints.\n",
    "* An example of such a problem might be\n",
    "\t$$ \\min (x_1 -2)^2 + (x_2 -1)^2 \\quad  s.t.\\quad \\begin{array} x_{1}^2 -x_2 \\leq 0 \\\\\n",
    "                                                              x_1 +x_2 \\leq 2 \\end{array}\n",
    "                                                              $$\n",
    "* Here is a picture of that problem taken from the textbook [@nocedal-wright] ( for copyright reasons, I cannot show this in the online version of the slides. ):\n",
    "\n",
    "![Figure 1.1 in [@nocedal-wright]](figs-restricted/feasible-region.png) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "# Kinds of problems considered\n",
    "\n",
    "* Don't talk about stochastic optimization methods:\n",
    "\t* Simluated Annealing\n",
    "\t* MCMC \n",
    "\t* other Stochastic Search Methods\n",
    "\t* A gentle introduction is \t[@casella-R]\n",
    "\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "# Transportation Problem\n",
    "\n",
    "> A chemical company has two factories $F_1,F_2$ and a dozen retail outlets $R_1,\\dots,R_{12}$. Each factory $i$ can produce at most $a_i$ tons of output each week. Each retail outlet $j$ has a weekly demand of $b_j$ tons per week. The cost of shipping from $F_i$ to $R_j$ is given by $c_{ij}$.\n",
    "> How much of the product to ship from each factory to each outlet, minimize cost, and satisfy all constraints? let's call $x_{ij}$ the number of tons shipped from $i$ to $j$.\n",
    "\n",
    "![Figure 1.2 in [@nocedal-wright]](figs-restricted/transportation.png)\n",
    "\n",
    ". . .\n",
    "\n",
    "* A mathematical formulation of this problem is\n",
    "\t$$ \\begin{align}\n",
    "\t\t\\min \\sum_{ij} c_{ij} x_{ij} \\\\\n",
    "\t\t\\text{subject to} \\sum_{j=1}^{12} x_{ij} \\leq a_i,\\quad i=1,2 \\\\\n",
    "\t\t\\sum_{i=1}^2  x_{ij} \\geq b_j,\\quad j=1,\\dots,12  \\\\\n",
    "\t\tx_{ij} \\geq 0, \\quad i=1,2,j=1,\\dots,12\n",
    "\t\t\\end{align}\n",
    "\t\t$$\n",
    "\n",
    "* This is called a *linear programming* problem, because both objective function and all constrains are linear.\n",
    "* With any of those being nonlinear, we would call this a non-linear problem.\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "# Constrained vs Unconstrained\n",
    "\n",
    "* There are many applications of both in economics.\n",
    "* Unconstrained: maximimum likelihood\n",
    "* Constrained: MPEC\n",
    "* It is sometimes possible to transform a constrained problem into an unconstrained one.\n",
    "\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "# Convexity\n",
    "\n",
    "* Convex problems are easier to solve.\n",
    "* What is convex?\n",
    "\n",
    "> A set $S\\in\\mathbb{R}^n$ is convex if the straight line segment connecting any two points in $S$ lies entirely inside $S$.\n",
    "> A function $f$ is a convex function, if its domain $S$ is a convex set, and for any two points $x,y \\in S$, we have that\n",
    "\t$$ f(\\alpha x + (1-\\alpha)y) \\leq \\alpha f(x) + (1-\\alpha) f(y) $$\n",
    "\tfor all $\\alpha \\in [0,1]$\n",
    "\n",
    "* Simple instances of convex sets are the unit ball $\\{y \\in \\mathbb{R}^n, \\Vert y\\Vert_2 \\leq 1\\}$, and any set defined by linear equalities and inequalities.\n",
    "* *convex Programming* describes a special case of the introductory minimizatin problem where \n",
    "\t* the objective function is convex, \n",
    "\t* the equality constrains are linear, and \n",
    "\t* the inequality constraints are concave.\n",
    "\n",
    "---------------\n",
    "\n",
    "# Optimization Algorithms\n",
    "\n",
    "* All of the algorithms we are going to see employ some kind of *iterative* proceedure. \n",
    "* They try to improve the value of the objective function over successive steps.\n",
    "* The way the algorithm goes about generating the next step is what distinguishes algorithms from one another.\n",
    "\t* Some algos only use the objective function\n",
    "\t* Some use both objective and gradients\n",
    "\t* Some add the Hessian\n",
    "\t* and many variants more\n",
    "\n",
    ". . .\n",
    "\n",
    "## Desirable Features of any Algorithm\n",
    "\n",
    "* Robustness: We want good performance on a wide variety of problems in their class, and starting from *all* reasonable starting points.\n",
    "* Efficiency: They should be fast and not use an excessive amount of memory.\n",
    "* Accuracy: They should identify the solution with high precision.\n",
    "\n",
    ". . .\n",
    "\n",
    "## A Word of Caution\n",
    "\n",
    "* You should **not** normally attempt to write a numerical optimizer for yourself.\n",
    "* Entire generations of Applied Mathematicians and other numerical pro's have worked on those topics before you, so you should use their work.\n",
    "\t* Any optimizer you could come up with is probably going to perform below par, and be highly likely to contain mistakes.\n",
    "\t* Don't reinvent the wheel.\n",
    "* That said, it's very important that we understand some basics about the main algorithms, because your task is **to choose from the wide array of available ones**.\n",
    "\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "# Unconstrained Optimization: What is a solution?\n",
    "\n",
    "* A typical unconstrained optimization problem will look something like this:\n",
    "\t$$ \\min_x f(x),\\quad x\\in \\mathbb{R}^n $$\n",
    "\tand where $f : \\mathbb{R}^n \\mapsto \\mathbb{R}$ is a smooth function.\n",
    "* In general, we would always like to find a *global* minimizer, i.e.\n",
    "<div class=\"center\" style=\"width: auto; margin-left: auto; margin-right: auto;\">a point $x^*$ where $f(x^*) \\leq f(x)\\quad \\forall x$</div>\n",
    "* Since our algorithm is not going to visit many points in $\\mathbb{R}^n$ (or so we hope), we can never be totally sure that we find a global optimizer.\n",
    "* Most optimizers can only find a *local* minimizer. That is a point\n",
    " <div class=\"center\" style=\"width: auto; margin-left: auto; margin-right: auto;\">$x^*$ where $f(x^*) \\leq f(x)\\quad \\forall x \\in \\mathcal{N}$ where $\\mathcal{N}$ is a neighborhood around $x^*$.</div>\n",
    "\n",
    "* Global minization can be very hard sometimes.\n",
    "\n",
    "![Global min at $f(512, 404.2319)$. By Gaortizg [GFDL](http://www.gnu.org/copyleft/fdl.html) or [CC BY-SA 3.0](http://creativecommons.org/licenses/by-sa/3.0), via Wikimedia Commons](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Eggholder_function.pdf/page1-800px-Eggholder_function.pdf.jpg) \n",
    "\n",
    "-----------------\n",
    "\n",
    "# (Unconstrained) Optimization in `Julia`\n",
    "\n",
    "* Umbrella Organisation: [`http://www.juliaopt.org`](http://www.juliaopt.org)\n",
    "\t* We will make ample use of this when we talk about constrained optimsation.\n",
    "\t* The Julia Interface to the very well established [C-Library NLopt](http://ab-initio.mit.edu/wiki/index.php/NLopt) is called [`NLopt.jl`](https://github.com/JuliaOpt/NLopt.jl). One could use `NLopt` without constraints in an unconstrained problem.\n",
    "* [`Roots.jl`](https://github.com/JuliaLang/Roots.jl): Simple algorithms that find the zeros of a univariate function.\n",
    "* Baseline Collection of unconstrained optimization algorithms: [`Optim.jl`](https://github.com/JuliaOpt/Optim.jl)\n",
    "\n",
    "\n",
    "-----------------\n",
    "\n",
    "# Introducing [`Optim.jl`](https://github.com/JuliaOpt/Optim.jl)\n",
    "\n",
    "* Multipurpose unconstrained optimization package \n",
    "\t* provides 8 different algorithms\n",
    "\t* univariate optimization without derivatives\n",
    "\n",
    "### Introducing [Rosenbrock's Banana](https://en.wikipedia.org/wiki/Rosenbrock_function) function\n",
    "\n",
    "The Banana function is defined by \n",
    "\t$$ f(x,y) = (a-x)^2  + b(y-x^2)^2  $$\n",
    "\n",
    "![Banana for $a = 0$. By Gaortizg [GFDL](http://www.gnu.org/copyleft/fdl.html) or [CC BY-SA 3.0](http://creativecommons.org/licenses/by-sa/3.0), via Wikimedia Commons](https://upload.wikimedia.org/wikipedia/commons/3/32/Rosenbrock_function.svg)\n",
    "\n",
    "### What is the minimum of that function?\n",
    "\n",
    "* For $a=1,b=100$, what is the global minimum of that function?\n",
    "* What are the inputs one needs to supply to an algorithm in a more general example?\n",
    "\n",
    "\n",
    "------------\n",
    "\n",
    "# Rosenbrock Banana and Optim.jl\n",
    "\n",
    "* We will use `Optim` for the rest of this lecture.\n",
    "* We need to supply the objective function and - depending on the solution algorithm - the gradient and hessian as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "function rosenbrock(x::Vector)\n",
    "    return (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2\n",
    "end\n",
    "\n",
    "function rosenbrock_gradient!(x::Vector, storage::Vector)\n",
    "    storage[1] = -2.0 * (1.0 - x[1]) - 400.0 * (x[2] - x[1]^2) * x[1]\n",
    "    storage[2] = 200.0 * (x[2] - x[1]^2)\n",
    "end\n",
    "\n",
    "function rosenbrock_hessian!(x::Vector, storage::Matrix)\n",
    "    storage[1, 1] = 2.0 - 400.0 * x[2] + 1200.0 * x[1]^2\n",
    "    storage[1, 2] = -400.0 * x[1]\n",
    "    storage[2, 1] = -400.0 * x[1]\n",
    "    storage[2, 2] = 200.0\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "# Comparison Methods\n",
    "\n",
    "* We will now look at a first class of algorithms, which are very simple, but sometimes a good starting point.\n",
    "* They just *compare* function values.\n",
    "* *Grid Search* : Compute the objective function at $G=\\{x_1,\\dots,x_N\\}$ and pick the highest value of $f$. \n",
    "\t* This is very slow.\n",
    "\t* It requires large $N$.\n",
    "\t* But it's robust (will find global optimizer for large enough $N$)\n",
    "\n",
    ". . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "# grid search on rosenbrock\n",
    "grid = collect(-1.0:0.1:3);\n",
    "grid2D = [[i;j] for i in grid,j in grid];\n",
    "val2D = map(rosenbrock,grid2D);\n",
    "r = findmin(val2D);\n",
    "println(\"grid search results in minimizer = $(grid2D[r[2]])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "# The Golden Ratio or Bracketing Search for 1D problems\n",
    "\n",
    "* A derivative-free method\n",
    "* a Bracketing method\n",
    "\t* find the local minimum of $f$ on $[a,b]$\n",
    "\t* select 2 interior points $c,d$ such that $a<c<d<b$\n",
    "\t\t* $f(c) \\leq f(d) \\implies$ min must lie in $[a,d]$. replace $b$ with $d$, start again with $[a,d]$\n",
    "\t\t* $f(c) > f(d) \\implies$ min must lie in $[c,b]$. replace $a$ with $c$, start again with $[c,b]$\n",
    "\t* how to choose $b,d$ though?\n",
    "\t* we want the length of the interval to be independent of whether we replace upper or lower bound\n",
    "\t* we want to reuse the non-replaced point from the previous iteration. \n",
    "\t* these imply the golden rule:\n",
    "\t* new point $x_i = a + \\alpha_i (b-a)$, where $\\alpha_1 = \\frac{3-\\sqrt{5}}{2},\\alpha_2=\\frac{\\sqrt{5}-1}{2}$\n",
    "\t* $\\alpha_2$ is known as the *golden ratio*, well known for it's role in renaissance art.\n",
    "\n",
    "### Bracketing Search in Julia\n",
    "\n",
    "* The package [`Optim.jl`](https://github.com/JuliaOpt/Optim.jl) provides an implementation of \"Brent's Method\" as well as the golden section search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "using Optim\n",
    "using Gadfly\n",
    "f(x) = exp(x) - x^4\n",
    "minf(x) = -f(x)\n",
    "plot(f,0,2)\n",
    "brent = optimize(minf,0,2,method=:brent)\n",
    "golden = optimize(minf,0,2,method=:golden_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* how well does this do with many local minima?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "g(x) = exp(x) - x^4 +sin(40*x)\n",
    "ming(x) = -g(x)\n",
    "plot(g,0,2)\n",
    "grid = collect(0:0.0001:2);\n",
    "v,idx  = findmax(Float64[g(x) for x in grid])\n",
    "println(\"grid maximizer is $(grid[idx])\")\n",
    "golden = optimize(ming,0,2,method=:golden_section)\n",
    "brent = optimize(ming,0,2,method=:brent)\n",
    "using Base.Test\n",
    "@test_approx_eq\t grid[idx] golden.minimum\n",
    "@test_approx_eq\t grid[idx] brent.minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Not *very* well at all. You can easily see that this method only works for unimodal functions. \n",
    "* We get trapped in a local minimum here.\n",
    "\n",
    "---------------\n",
    "\n",
    "# Bracketing for Multidimensional Problems: Nelder-Mead\n",
    "\n",
    "* The Goal here is to find the simplex containing the local minimizer $x^*$\n",
    "* In the case where $f$ is n-D, this simplex has $n+1$ vertices\n",
    "* In the case where $f$ is 2-D, this simplex has $2+1$ vertices, i.e. it's a triangle.\n",
    "* The method proceeds by evaluating the function at all $n+1$ vertices, and by replacing the worst function value with a new guess.\n",
    "* this can be achieved by a sequence of moves:\n",
    "\t* reflect\n",
    "\t* expand\n",
    "\t* contract\n",
    "\t* shrink\n",
    "\tmovements.\n",
    "\n",
    "<div class=\"center\" style=\"width: auto; margin-left: auto; margin-right: auto;\"> ![](figs/neldermeadsteps.gif) </div>\n",
    "\n",
    "* this is a very popular method. The matlab functions `fmincon` and `fminsearch` implements it.\n",
    "* When it works, it works quite fast.\n",
    "* No derivatives required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "using Optim\n",
    "optimize(rosenbrock, [0.0, 0.0], method = :nelder_mead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* But.\n",
    "\n",
    "---------------\n",
    "\n",
    "# Bracketing for Multidimensional Problems: Comment on Nelder-Mead\n",
    "\n",
    "> Lagarias et al. (SIOPT, 1999):\n",
    "At present there is no function in any dimension greater than one, for which the original Nelder-Mead algorithm has been proved to converge to a minimizer.\n",
    "\n",
    ">Given all the known inefficiencies and failures of the Nelder-Mead algorithm [...], one might wonder why it is used at all, let alone why it is so extraordinarily popular.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "# Reminder: Optimality Conditions \n",
    "\n",
    "### Notation\n",
    "\n",
    "\n",
    "* Unless otherwise noted, we have $x \\in \\mathbb{R}^n$ as an $n$ element vector.\n",
    "* The **gradient** of a function $f : \\mathbb{R}^n \\mapsto \\mathbb{R}$ is denoted $\\nabla f:\\mathbb{R}^n \\mapsto \\mathbb{R}^n$ a it returns a vector\n",
    "\t$$ \\nabla f(x) = \\left(\\frac{\\partial f}{\\partial x_1}(x),\\frac{\\partial f}{\\partial x_2}(x),\\dots,\\frac{\\partial f}{\\partial x_n}(x) \\right) $$\n",
    "* It's **hessian** is a function denoted $\\nabla^2 f(x)$ or $H_f :\\mathbb{R}^n \\mapsto \\mathbb{R}^{n\\times n}$ and returns an $(n,n)$ matrix given by\n",
    "\t$$  H_f(x) = \\left( \\begin{array}{c} \\frac{\\partial^2 f}{\\partial x_1 \\partial x_1}(x)  &  \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1}(x) & \\dots & \\frac{\\partial^2 f}{\\partial x_n \\partial x_1}(x) \\\\\n",
    "\t                     \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2}(x)  &  \\frac{\\partial^2 f}{\\partial x_2 \\partial x_2}(x) & \\dots & \\frac{\\partial^2 f}{\\partial x_n \\partial x_2}(x) \\\\\n",
    "\t                     \\vdots & \\vdots & \\dots & \\vdots \\\\\n",
    "\t                     \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n}(x)  &  \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n}(x) & \\dots & \\frac{\\partial^2 f}{\\partial x_n \\partial x_n}(x) \n",
    "\t                     \\end{array}\n",
    "\t             \\right)\n",
    "\t$$\n",
    "\n",
    "### Optimality Conditions\n",
    "\n",
    "* **First Order Necessary Conditions**:\n",
    "\tIf $f$ is continously differentiable and $x^*$ is a local minimizer of $f$, then $\\nabla f(x^*) = 0$.\n",
    "* **Second Order Necessary Conditions**:\n",
    "\tIf $f$ is twice continuously differentiable and $x^*$ is a local minimizer of $f$, then $\\nabla f(x^*) = 0$ *and* $H_f (x^*)$ is positive semi-definite, i.e. we have $s^T H_f (x^*) s \\geq 0$ for all $s \\in \\mathbb{R}^n$.\n",
    "* **Second Order Sufficient Conditions**:\n",
    "\tIf $f$ is twice continuously differentiable and at $x^*$ we have that $\\nabla f(x^*) = 0$ *and* $H_f (x^*)$ is positive definite, i.e. $s^T H_f (x^*) s > 0,s\\neq 0$ then $x^*$ is a local minimizer of $f$.\n",
    "* More sophisticated solvers make ample use of those.\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "# Reminder: Sufficient Conditions for Global Optimality \n",
    "\n",
    "* If $f$ is convex, then any local minimizer $x^*$ is a global minimizer.\n",
    "*  If $f$ is convex and differentiable on $\\mathbb{R}^n$ , then any point $x^*$ is a global minimizer if and only if it is a stationary point, i.e. if f$\\nabla f(x^*) = 0$.\n",
    "\n",
    "# Reminder: Taylor's Theorem\n",
    "\n",
    "* Many of the ensuing methods are based on Taylor's theorem, so let's remind ourselves of it:\n",
    "\n",
    "<!-- \tf(x) & = & f(x^0) + \\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i} (x^0) (x_i - x^0) \\\\\n",
    "\t     & + & \\frac{1}{2} + \\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i} (x^0) (x_i - x^0) \\\\\n",
    " -->\n",
    "\n",
    "* Suppose that $f \\in C^{n+1}[a,b]$, and $x,x^0 \\in [a,b]$. Then\n",
    "\t$$ \\begin{align}\n",
    "\tf(x)  = & f(x^0) + f'(x^0)(x - x^0) + f''(x^0)\\frac{(x- x^0)^2}{2}\\\\\n",
    "\t      + & \\dots + f^{(n)}(x^0)\\frac{(x - x^0)^n}{n!} + R_{n+1}(x) \n",
    "\t     \\end{align}\n",
    "\t     $$\n",
    "    where $R_{n+1}(x) = \\mathcal{o}\\left(\\Vert (x-x^0) \\Vert^{n+1}\\right)$ is reminder term that converges at a rate $n+1$ to zero, i.e. \n",
    "* we say a function $f$ is $\\mathcal{o}(\\Vert x \\Vert^n)$ if $\\lim_{x\\to 0}\\Vert f(x) \\Vert / \\Vert x \\Vert^n =0$.\n",
    "* we say a function $f$ is $\\mathcal{O}(\\Vert x \\Vert^n)$ if $\\lim_{x\\to 0}\\Vert f(x) \\Vert / \\Vert x \\Vert^n < \\infty$\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "# A quick Note on Computing Derivatives\n",
    "\n",
    "* Finite Differences\n",
    "* Automatic Differentiation\n",
    "* We will talk about this in a separate session.\n",
    "* For now just remember that if we don't supply analytic gradients, and the algorithm requires them, this often triggers a numerical approximation of the gradient known as finite differences. This is most of the times a slow proceedure.\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "# Two Strategies: Line Search and Trust Region\n",
    "\n",
    "* We only provide an overview of methods here. If you want to *really* know the details about those algorithms, I invite you to consult [@nocedal-wright].\n",
    "\n",
    "### The Line Search Strategy\n",
    "\n",
    "* An algorithm from the line search class  chooses a direction $p_k \\in \\mathbb{R}^n$ and searches along that direction starting from the current iterate $x_k \\in \\mathbb{R}^n$ for a new iterate $x_{k+1} \\in \\mathbb{R}^n$ with a lower function value.\n",
    "* After deciding on a direction $p_k$, one needs to decide the *step length* $\\alpha$ to travel by solving\n",
    "\t$$ \\min_{\\alpha>0} f(x_k + \\alpha p_k) $$\n",
    "* In practice, solving this exactly is too costly, so algos usually generate a sequence of trial values $\\alpha$ and pick the one with the lowest $f$.\n",
    "\n",
    "\n",
    "### The Trust Region Strategy\n",
    "\n",
    "* Here we construct a *model function* $m_k$ that is similar to $f$ around $x_k$.\n",
    "* We acknowledge that $m_k$ is decent approximation of $f$ only in some *region*.\n",
    "* The problem is then to find a candidate step length $p$ by solving\n",
    "\t$$ \\min_p m_k (x_k + p) $$ where $x_k + p$ lies inside the trust region.\n",
    "* If candidate $p$ does not produce a value lower than $f(x_k)$, we must have had a too large trust region, shrink it, and do it again.\n",
    "* Usually the trust region is a ball $\\Vert p \\Vert_2 \\leq \\Delta$, where $\\Delta$ is called the *trust region radius*, but elliptical and box regions are possible.\n",
    "* A common definition of the model function is a quadratic of the form\n",
    "\t$$ m_k(x_k + p) = f(x_k) + p^T \\nabla f(x_k) + \\frac{1}{2} p^T B(x_k) p $$\n",
    "\twhere gradient and matrix $B(x_k)$ are evaluated at the current iterate, so the model function is in agreement to first order with $f$ at the current guess.\n",
    "* The matrix $B(x_k)$ is either the Hessian $H_f$ or some approximation to it.\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "# Trust Region Example\n",
    "\n",
    "* Suppose we have $f(x) = 10(x_2 - x_1^2)^2 + (1-x_1)^2$. At point $x_k= (0,1)$ gradient and hessian are:\n",
    "* ?\n",
    "\n",
    ". . .\n",
    "\n",
    "$$ \\nabla f(x_k) = \\left[ \\begin{array}{c} -2 \\\\ 20 \\end{array} \\right], \\quad \\quad \\nabla^2 f(x_k) = \\left[ \\begin{array}{c} -38 & 0 \\\\ 0 & 20 \\end{array} \\right] $$\n",
    "\n",
    "![Figure 2.4 of [@nocedal-wright]](figs-restricted/trust-region.png)\n",
    "\n",
    "* In this figure, we use $B(x_k) = \\nabla^2 f(x_k)$. \n",
    "* After each unsuccesful step, the new candidate step will be shorter, and will go in a different direction\n",
    "* This is the main difference to line search methods.\n",
    "* Main difference between the two methods: order in which they change *direction* and *step length*\n",
    "\t* line search fixes direction $p_k$ and finds right distance $\\alpha_k$\n",
    "\t* trust region fixes an appropriate radius $\\Delta_k$\n",
    "\n",
    "---------------\n",
    "\n",
    "# Line Search Methods: Which Direction to go?\n",
    "\n",
    "\n",
    "### Steepest Descent\n",
    "\n",
    "* The direction $-\\nabla f(x_k)$ is an obvious choice: Among all possible directions, along this one $f$ decreases most rapidly.\n",
    "* This claim can be verified using Taylor's theorem.\n",
    "* The **steepest descent method** is a line search method that moves along\n",
    "\t$$ p_k = -\\nabla f(x_k) $$\n",
    "* The step length $\\alpha_k$ can be chosen in many different ways.\n",
    "* There are many other *descent* directions, steepest descent is but one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "optimize(rosenbrock, rosenbrock_gradient!, [0.0, 0.0], method = :gradient_descent)\n",
    "optimize(rosenbrock, rosenbrock_gradient!, [0.0, 0.0], method = :gradient_descent,iterations=5000)\n",
    "optimize(rosenbrock, rosenbrock_gradient!, [0.0, 0.0], method = :gradient_descent,iterations=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 2.5 of [@nocedal-wright]](figs-restricted/steepest-descent.png)\n",
    "\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "# Line Search Methods: The **Newton** Direction\n",
    "\n",
    "* Probably the most important descent direction.\n",
    "* In vector notation, the 2nd order taylor series approximation to $f(x_k + p)$ is\n",
    "\t$$ f(x_k + p) \\approx f(x_k) + p^T \\nabla f(x_k) + \\frac{1}{2} p^T \\nabla^2 f(x_k) p \\equiv m_k(p) $$\n",
    "* the Newton direction is obtained by finding the vector $p$ that minimizes $m_k(p)$, i.e. by setting the derivative of $m_k(p)$ to zero.\n",
    "* We obtain\n",
    "\t$$ p_k^N = -(\\nabla^2 f(x_k))^{-1} \\nabla f(x_k)  $$\n",
    "* The newton direction is reliable if the discrepancy between truth and model $m$ is not too large at $x_k$.\n",
    "* The biggest drawback is the need to compute the Hessian. This can be difficult analytically at times, and overly expensive numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "optimize(rosenbrock, rosenbrock_gradient!, rosenbrock_hessian!, [0.0, 0.0], method = :newton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "# Quasi-Newton Methods\n",
    "\n",
    "* In response to the difficulties of getting the Hessian, quasi-newton methods propose to approximate $B(x_k)$ with something *similar* to the hessian.\n",
    "* Taylors Theorem implies that \n",
    "\t$$ \\nabla^2 f(x_{k+1} - x_{k}) \\approx \\nabla f(x_{k+1}) - \\nabla f(x_k) $$\n",
    "\tand so we choose a $B$ matrix that mimics this property.\n",
    "* This leads to the *secant condition*\n",
    "\t$$ B_{k+1} (x_{k+1} - x_{k}) = f(x_{k+1}) - \\nabla f(x_k) $$\n",
    "* There are different ways to update the hessian in this way.\n",
    "* One of the best known is the BFGS method (after Broydon, Fletcher, Goldfarb and Shanno).\n",
    "* Those methods get the search direction by using $B_k$ instead of the exact Hessian, i.e.\n",
    "\t$$ p_k = -B_k^{-1} \\nabla f(x_k)  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "julia"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "optimize(rosenbrock, rosenbrock_gradient!, rosenbrock_hessian!, [0.0, 0.0], method = :bfgs)\n",
    "# low memory BFGS\n",
    "optimize(rosenbrock, rosenbrock_gradient!, rosenbrock_hessian!, [0.0, 0.0], method = :l_bfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "\n",
    "# Practical Considerations\n",
    "\n",
    "## Stopping criteria\n",
    "\n",
    "* In all of the above examples, we did not alter the default values for stopping criteria.\n",
    "* There are different things you could focus on as a stopping criterion with `Optim`, and similarly in most solver packages.\n",
    "\t* `xtol`: changes in $x$ from one iterate to the next\n",
    "\t* `ftol`: perentage changes in $f$ from one iterate to the next\n",
    "\t* `grtol`: absolute value of the gradient beign smaller than this number.\n",
    "\n",
    "\n",
    "-----------------\n",
    "\n",
    "# Some Applications in Economics\n",
    "\n",
    "* Maximum Likelihood Estimation\n",
    "* The Nested Fixed Point Algorithm\n",
    "\t* [@rust-bus] is a maximum likelihood estimation with an inner loop that solves a dynamic programming problem.\n",
    "\t* [@BLP] is a GMM estimation with an inner fixed point problem.\n",
    "\n",
    "\n",
    "\n",
    "------------\n",
    "\n",
    "# References"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
